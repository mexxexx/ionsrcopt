{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our preliminary tests showed, that Optigrid performed well on Data of November 2018. In this notebook we will explore a few other months and look for similarities and descrepancies in the results. We will use preprocessed data, where things like source stability and voltage breakdowns are indicated. Moreover, for now we will limit ourselfs to stable running sources, i.e. time periods with a low variance and a high current in the BCT25. We use the already preprocessed datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module loading\n",
    "We use the Python modules from the ionsrcopt package that will be loaded in the next cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../ionsrcopt/import_notebooks/Setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../ionsrcopt/import_notebooks/Clustering.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to specifiy all the columns we are interested in. There are three types: Parameters, these are the ones that will be clustered later on, Measurments and columns from preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = [SourceFeatures.TIMESTAMP]\n",
    "parameters = [\n",
    "        SourceFeatures.BIASDISCAQNV, \n",
    "        SourceFeatures.GASAQN, \n",
    "        SourceFeatures.OVEN1AQNP,\n",
    "        SourceFeatures.SAIREM2_FORWARDPOWER,\n",
    "        SourceFeatures.SOLINJ_CURRENT,\n",
    "        SourceFeatures.SOLCEN_CURRENT,\n",
    "        SourceFeatures.SOLEXT_CURRENT,\n",
    "        SourceFeatures.SOURCEHTAQNI,\n",
    "        SourceFeatures.BCT25_CURRENT]\n",
    "measurements = []\n",
    "preprocessing = [\n",
    "        ProcessingFeatures.SOURCE_STABILITY, \n",
    "        ProcessingFeatures.HT_VOLTAGE_BREAKDOWN, \n",
    "        ProcessingFeatures.DATAPOINT_DURATION,\n",
    "        ProcessingFeatures.SOURCE_RUNNING]\n",
    "\n",
    "columns_to_load = time + parameters + measurements + preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, specify the important files.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '../Data_Preprocessed/'\n",
    "input_files = ['Jan2018.csv', 'Feb2018.csv', 'Mar2018.csv', 'Apr2018.csv', 'May2018.csv', 'Jun2018.csv', 'Jul2018.csv', 'Aug2018.csv', 'Sep2018.csv', 'Oct2018.csv', 'Nov2018.csv']\n",
    "input_paths = [input_folder + f for f in input_files]\n",
    "output_folder = '../Data_Clustered/'\n",
    "output_file = 'JanNov2018.csv'\n",
    "output_path = output_folder + output_file\n",
    "\n",
    "cluster_logfile = output_folder + 'cluster_runs.log'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and load them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = read_data_from_csv(input_paths, columns_to_load, None)\n",
    "df_total = fill_columns(df_total, None, fill_nan_with_zeros=True)\n",
    "df_total = convert_column_types(df_total)\n",
    "df_total.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5824993, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we select what data we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_values(df_total, parameters, selector):\n",
    "    data = df_total.loc[selector, parameters].values\n",
    "    weights = df_total.loc[selector, ProcessingFeatures.DATAPOINT_DURATION].values\n",
    "    return data, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is ready we can begin clustering. But first we standard scale it, so that all parameters have the same variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def scale_values(values, scaler):\n",
    "    if not scaler:\n",
    "        scaler = preprocessing.StandardScaler().fit(values)\n",
    "    values_scaled = scaler.transform(values)\n",
    "    return scaler, values_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters for optigrid can be chosen by visually examening the distribution of normalized data, see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=len(parameters)\n",
    "q=1\n",
    "max_cut_score = 0.1\n",
    "noise_level = 0.05\n",
    "\n",
    "optigrid_params = {\n",
    "    'd' : d, \n",
    "    'q' : q, \n",
    "    'max_cut_score' : max_cut_score, \n",
    "    'noise_level' : noise_level,\n",
    "    'kde_bandwidth' : 0.06,\n",
    "    'verbose' : True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_optigrid(values_scaled, weights, optigrid_params):\n",
    "    optigrid = Optigrid(**optigrid_params)\n",
    "    optigrid.fit(values_scaled, weights)\n",
    "    return optigrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the clusters are found, we set an according column in the original dataframe containing all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_clusters_df_total(df_total, optigrid, num_values, selector):\n",
    "    clusters = np.zeros(num_values)\n",
    "\n",
    "    for i, cluster in enumerate(optigrid.clusters):\n",
    "        clusters[cluster] = i\n",
    "    df_total.loc[selector, ProcessingFeatures.CLUSTER] = clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we bundle all these steps together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(df_total, parameters, source_stable, optigrid_params):\n",
    "    print(\"Starting clustering for source stability {}\".format(source_stable))\n",
    "    source_stability = df_total[ProcessingFeatures.SOURCE_STABILITY] == source_stable\n",
    "    voltage_breakdown_selection = df_total[ProcessingFeatures.HT_VOLTAGE_BREAKDOWN] > 0\n",
    "    source_running = df_total[ProcessingFeatures.SOURCE_RUNNING] == True\n",
    "    \n",
    "    selector = source_stability & ~voltage_breakdown_selection & source_running\n",
    "    values, weights = select_values(df_total, parameters, selector) # First, get the data without breakdowns,\n",
    "    scaler, values_scaled = scale_values(values, None) # standard scale it\n",
    "    optigrid = run_optigrid(values_scaled, weights, optigrid_params) # and compute the clusters.\n",
    "    assign_clusters_df_total(df_total, optigrid, len(values), selector) # Then, assign the found clusters to the original dataframe in a new column 'optigrid_clusters'\n",
    "    \n",
    "    print(\"Scoring voltage breakdowns\")\n",
    "    selector = source_stability & voltage_breakdown_selection & source_running\n",
    "    values, weights = select_values(df_total, parameters, selector) # Now, get the datapoints when the voltage broke down\n",
    "    _, values_scaled = scale_values(values, scaler) # scale it to the same ranges\n",
    "    scored_samples = optigrid.score_samples(values_scaled) # and find the corresponding clusters.\n",
    "    df_total.loc[selector, ProcessingFeatures.CLUSTER] = scored_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting clustering for source stability 1\n",
      "Found following cuts: [(-1.5586662075736306, 2, 3.5424831913455504e-18)]\n",
      "Evaluating subgrid: 100.00% of datapoints\n",
      "Found following cuts: [(-0.536211042693167, 1, 8.140809629402368e-38)]\n",
      "Evaluating subgrid: 4.99% of datapoints\n",
      "Found cluster 0\n",
      "Evaluating subgrid: 4.99% of datapoints\n",
      "Found following cuts: [(0.4716584670423257, 1, 0.0026910531611852224)]\n",
      "Evaluating subgrid: 3.04% of datapoints\n",
      "Found cluster 1\n",
      "Evaluating subgrid: 3.04% of datapoints\n",
      "Found cluster 2\n",
      "Found cluster: 3.04% of datapoints\n",
      "Found cluster: 4.99% of datapoints\n",
      "Evaluating subgrid: 100.00% of datapoints\n",
      "Found following cuts: [(2.576037734445899, 5, 5.1615825937021344e-18)]\n",
      "Evaluating subgrid: 95.01% of datapoints\n",
      "Found following cuts: [(-2.4684997495978767, 3, 5.357567430109741e-43)]\n",
      "Evaluating subgrid: 90.66% of datapoints\n",
      "Found following cuts: [(0.6367034912109375, 5, 3.542028702909208e-05)]\n",
      "Evaluating subgrid: 6.87% of datapoints\n",
      "Found following cuts: [(-1.4965935186906294, 6, 0.02398394496642031)]\n",
      "Evaluating subgrid: 2.47% of datapoints\n",
      "Found cluster 3\n",
      "Evaluating subgrid: 2.47% of datapoints\n",
      "Found cluster 4\n",
      "Found cluster: 2.47% of datapoints\n",
      "Evaluating subgrid: 6.87% of datapoints\n",
      "Found following cuts: [(0.41454046422784985, 4, 0.0006758484749028758)]\n",
      "Evaluating subgrid: 4.40% of datapoints\n",
      "Found cluster 5\n",
      "Evaluating subgrid: 4.40% of datapoints\n",
      "Found following cuts: [(1.348107849106644, 5, 0.001126088762343014)]\n",
      "Evaluating subgrid: 2.87% of datapoints\n",
      "Found cluster 6\n",
      "Evaluating subgrid: 2.87% of datapoints\n",
      "Found cluster 7\n",
      "Found cluster: 2.87% of datapoints\n",
      "Found cluster: 4.40% of datapoints\n",
      "Found cluster: 6.87% of datapoints\n",
      "Evaluating subgrid: 90.66% of datapoints\n",
      "Found following cuts: [(-3.953527710654519, 1, 2.7807826897713828e-14)]\n",
      "Evaluating subgrid: 83.78% of datapoints\n",
      "Found cluster 8\n",
      "Evaluating subgrid: 83.78% of datapoints\n",
      "Found following cuts: [(-0.08177432749006486, 6, 2.0129211991526702e-06)]\n",
      "Evaluating subgrid: 82.71% of datapoints\n",
      "Found following cuts: [(-0.963519811630249, 0, 7.16620538134757e-05)]\n",
      "Evaluating subgrid: 38.01% of datapoints\n",
      "Found following cuts: [(1.0743776830759915, 2, 0.002190399770851334)]\n",
      "Evaluating subgrid: 8.47% of datapoints\n",
      "Found following cuts: [(0.34041662770088277, 1, 0.006581220993586974)]\n",
      "Evaluating subgrid: 6.08% of datapoints\n",
      "Found following cuts: [(-0.22169745510274713, 5, 0.012414100202797887)]\n",
      "Evaluating subgrid: 2.51% of datapoints\n",
      "Found cluster 9\n",
      "Evaluating subgrid: 2.51% of datapoints\n",
      "Found cluster 10\n",
      "Found cluster: 2.51% of datapoints\n",
      "Evaluating subgrid: 6.08% of datapoints\n",
      "Found following cuts: [(0.7867873762593125, 1, 0.016706642749588937)]\n",
      "Evaluating subgrid: 3.57% of datapoints\n",
      "Found cluster 11\n",
      "Evaluating subgrid: 3.57% of datapoints\n",
      "Found cluster 12\n",
      "Found cluster: 3.57% of datapoints\n",
      "Found cluster: 6.08% of datapoints\n",
      "Evaluating subgrid: 8.47% of datapoints\n",
      "Found cluster 13\n",
      "Found cluster: 8.47% of datapoints\n",
      "Evaluating subgrid: 38.01% of datapoints\n",
      "Found following cuts: [(0.7181978177542638, 5, 0.0002697508261362591)]\n",
      "Evaluating subgrid: 29.53% of datapoints\n",
      "Found following cuts: [(-0.44177685181299853, 5, 0.004977833966960326)]\n",
      "Evaluating subgrid: 26.42% of datapoints\n",
      "Found following cuts: [(0.9244442515903053, 1, 0.0021834609397844975)]\n",
      "Evaluating subgrid: 2.57% of datapoints\n",
      "Found cluster 14\n",
      "Evaluating subgrid: 2.57% of datapoints\n",
      "Found cluster 15\n",
      "Found cluster: 2.57% of datapoints\n",
      "Evaluating subgrid: 26.42% of datapoints\n",
      "Found following cuts: [(0.36540771614421486, 0, 0.009300803009445304)]\n",
      "Evaluating subgrid: 23.84% of datapoints\n",
      "Found following cuts: [(0.5504647577651824, 4, 0.0028824545394160383)]\n",
      "Evaluating subgrid: 5.52% of datapoints\n",
      "Found cluster 16\n",
      "Evaluating subgrid: 5.52% of datapoints\n",
      "Found following cuts: [(-1.3381469623006956, 6, 3.557081179402145e-05)]\n",
      "Evaluating subgrid: 3.55% of datapoints\n",
      "Found cluster 17\n",
      "Evaluating subgrid: 3.55% of datapoints\n",
      "Found following cuts: [(-0.060843364758925045, 0, 0.01144134750179667)]\n",
      "Evaluating subgrid: 2.57% of datapoints\n",
      "Found cluster 18\n",
      "Evaluating subgrid: 2.57% of datapoints\n",
      "Found cluster 19\n",
      "Found cluster: 2.57% of datapoints\n",
      "Found cluster: 3.55% of datapoints\n",
      "Found cluster: 5.52% of datapoints\n",
      "Evaluating subgrid: 23.84% of datapoints\n",
      "Found following cuts: [(0.835849014797596, 0, 0.007862442036429964)]\n",
      "Evaluating subgrid: 18.33% of datapoints\n",
      "Found following cuts: [(0.27733036213450957, 5, 0.004745106187010303)]\n",
      "Evaluating subgrid: 11.53% of datapoints\n",
      "Found following cuts: [(-0.9820789773054805, 6, 0.0030830023161876555)]\n",
      "Evaluating subgrid: 9.28% of datapoints\n",
      "Found following cuts: [(0.5641512988191663, 4, 0.004828076226076867)]\n",
      "Evaluating subgrid: 3.41% of datapoints\n",
      "Found cluster 20\n",
      "Evaluating subgrid: 3.41% of datapoints\n",
      "Found cluster 21\n",
      "Found cluster: 3.41% of datapoints\n",
      "Evaluating subgrid: 9.28% of datapoints\n",
      "Found following cuts: [(0.263792051058827, 1, 0.016010581901645525)]\n",
      "Evaluating subgrid: 5.87% of datapoints\n",
      "Found cluster 22\n",
      "Evaluating subgrid: 5.87% of datapoints\n",
      "Found cluster 23\n",
      "Found cluster: 5.87% of datapoints\n",
      "Found cluster: 9.28% of datapoints\n",
      "Evaluating subgrid: 11.53% of datapoints\n",
      "Found cluster 24\n",
      "Found cluster: 11.53% of datapoints\n",
      "Evaluating subgrid: 18.33% of datapoints\n",
      "Found following cuts: [(0.3693683869910963, 1, 0.004842558421872391)]\n",
      "Evaluating subgrid: 6.80% of datapoints\n",
      "Found cluster 25\n",
      "Evaluating subgrid: 6.80% of datapoints\n",
      "Found following cuts: [(-0.9740762240958936, 6, 0.0004587184251355247)]\n",
      "Evaluating subgrid: 4.07% of datapoints\n",
      "Found cluster 26\n",
      "Evaluating subgrid: 4.07% of datapoints\n",
      "Found following cuts: [(-0.634901989590038, 2, 0.0022628344959928336)]\n",
      "Evaluating subgrid: 3.12% of datapoints\n",
      "Found cluster 27\n",
      "Evaluating subgrid: 3.12% of datapoints\n",
      "Found cluster 28\n",
      "Found cluster: 3.12% of datapoints\n",
      "Found cluster: 4.07% of datapoints\n",
      "Found cluster: 6.80% of datapoints\n",
      "Found cluster: 18.33% of datapoints\n",
      "Found cluster: 23.84% of datapoints\n",
      "Found cluster: 26.42% of datapoints\n",
      "Evaluating subgrid: 29.53% of datapoints\n",
      "Found following cuts: [(-0.02171665731102529, 0, 0.0005127039628864782)]\n",
      "Evaluating subgrid: 3.12% of datapoints\n",
      "Found cluster 29\n",
      "Evaluating subgrid: 3.12% of datapoints\n",
      "Found cluster 30\n",
      "Found cluster: 3.12% of datapoints\n",
      "Found cluster: 29.53% of datapoints\n",
      "Found cluster: 38.01% of datapoints\n",
      "Evaluating subgrid: 82.71% of datapoints\n",
      "Found following cuts: [(0.6856617060574619, 4, 0.001539853763591572)]\n",
      "Evaluating subgrid: 44.70% of datapoints\n",
      "Found following cuts: [(0.41972469079374, 0, 0.0034987336409948544)]\n",
      "Evaluating subgrid: 42.49% of datapoints\n",
      "Found following cuts: [(-0.9897205612876199, 5, 0.009279368744366301)]\n",
      "Evaluating subgrid: 28.66% of datapoints\n",
      "Found following cuts: [(0.2107490668393146, 1, 0.0011559922174838744)]\n",
      "Evaluating subgrid: 3.24% of datapoints\n",
      "Found following cuts: [(-1.2912223953189272, 5, 0.010814530213870006)]\n",
      "Evaluating subgrid: 2.05% of datapoints\n",
      "Found cluster 31\n",
      "Evaluating subgrid: 2.05% of datapoints\n",
      "Found cluster 32\n",
      "Found cluster: 2.05% of datapoints\n",
      "Evaluating subgrid: 3.24% of datapoints\n",
      "Found cluster 33\n",
      "Found cluster: 3.24% of datapoints\n",
      "Evaluating subgrid: 28.66% of datapoints\n",
      "Found following cuts: [(0.0017593828114597088, 0, 0.01133036064735145)]\n",
      "Evaluating subgrid: 25.42% of datapoints\n",
      "Found following cuts: [(0.3544274610702436, 1, 0.00048636451373497354)]\n",
      "Evaluating subgrid: 20.16% of datapoints\n",
      "Found following cuts: [(0.03663212331858556, 4, 0.0014385112457428527)]\n",
      "Evaluating subgrid: 17.28% of datapoints\n",
      "Found following cuts: [(0.16837773539803247, 3, 0.0017738495915517784)]\n",
      "Evaluating subgrid: 16.37% of datapoints\n",
      "Found following cuts: [(-0.2376917600631714, 2, 3.5321215896885144e-13)]\n",
      "Evaluating subgrid: 3.54% of datapoints\n",
      "Found following cuts: [(-0.72461667609862, 0, 3.148505994670469e-06)]\n",
      "Evaluating subgrid: 2.71% of datapoints\n",
      "Found cluster 34\n",
      "Evaluating subgrid: 2.71% of datapoints\n",
      "Found cluster 35\n",
      "Found cluster: 2.71% of datapoints\n",
      "Evaluating subgrid: 3.54% of datapoints\n",
      "Found cluster 36\n",
      "Found cluster: 3.54% of datapoints\n",
      "Evaluating subgrid: 16.37% of datapoints\n",
      "Found following cuts: [(-0.8166795765153236, 0, 0.0018024185171553833)]\n",
      "Evaluating subgrid: 12.83% of datapoints\n",
      "Found cluster 37\n",
      "Evaluating subgrid: 12.83% of datapoints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found following cuts: [(-0.25164432959123095, 5, 0.0036273242021894175)]\n",
      "Evaluating subgrid: 10.79% of datapoints\n",
      "Found following cuts: [(-0.36382837548400415, 2, 0.0006747717591545009)]\n",
      "Evaluating subgrid: 7.22% of datapoints\n",
      "Found cluster 38\n",
      "Evaluating subgrid: 7.22% of datapoints\n",
      "Found following cuts: [(-1.2289728219009408, 4, 0.0047451462272256155)]\n",
      "Evaluating subgrid: 4.84% of datapoints\n",
      "Found cluster 39\n",
      "Evaluating subgrid: 4.84% of datapoints\n",
      "Found following cuts: [(1.0529433639362604, 6, 0.004247254585464666)]\n",
      "Evaluating subgrid: 3.83% of datapoints\n",
      "Found following cuts: [(-0.8960783507185752, 4, 0.004338945812992136)]\n",
      "Evaluating subgrid: 2.23% of datapoints\n",
      "Found cluster 40\n",
      "Evaluating subgrid: 2.23% of datapoints\n",
      "Found cluster 41\n",
      "Found cluster: 2.23% of datapoints\n",
      "Evaluating subgrid: 3.83% of datapoints\n",
      "Found cluster 42\n",
      "Found cluster: 3.83% of datapoints\n",
      "Found cluster: 4.84% of datapoints\n",
      "Found cluster: 7.22% of datapoints\n",
      "Evaluating subgrid: 10.79% of datapoints\n",
      "Found following cuts: [(-0.9214275075179157, 4, 0.001781911703968324)]\n",
      "Evaluating subgrid: 3.57% of datapoints\n",
      "Found following cuts: [(-0.4134441943124238, 0, 0.0010055212274001529)]\n",
      "Evaluating subgrid: 2.27% of datapoints\n",
      "Found cluster 43\n",
      "Evaluating subgrid: 2.27% of datapoints\n",
      "Found cluster 44\n",
      "Found cluster: 2.27% of datapoints\n",
      "Evaluating subgrid: 3.57% of datapoints\n",
      "Found cluster 45\n",
      "Found cluster: 3.57% of datapoints\n",
      "Found cluster: 10.79% of datapoints\n",
      "Found cluster: 12.83% of datapoints\n",
      "Found cluster: 16.37% of datapoints\n",
      "Evaluating subgrid: 17.28% of datapoints\n",
      "Found cluster 46\n",
      "Found cluster: 17.28% of datapoints\n",
      "Evaluating subgrid: 20.16% of datapoints\n",
      "Found cluster 47\n",
      "Found cluster: 20.16% of datapoints\n",
      "Evaluating subgrid: 25.42% of datapoints\n",
      "Found following cuts: [(0.13242318714507917, 1, 0.015544609347189594)]\n",
      "Evaluating subgrid: 5.26% of datapoints\n",
      "Found cluster 48\n",
      "Evaluating subgrid: 5.26% of datapoints\n",
      "Found cluster 49\n",
      "Found cluster: 5.26% of datapoints\n",
      "Found cluster: 25.42% of datapoints\n",
      "Found cluster: 28.66% of datapoints\n",
      "Evaluating subgrid: 42.49% of datapoints\n",
      "Found following cuts: [(-0.9156031464085435, 5, 1.237726003600349e-05)]\n",
      "Evaluating subgrid: 13.83% of datapoints\n",
      "Found following cuts: [(-0.6109259863092442, 2, 0.07463602650958705)]\n",
      "Evaluating subgrid: 5.33% of datapoints\n",
      "Found cluster 50\n",
      "Evaluating subgrid: 5.33% of datapoints\n",
      "Found cluster 51\n",
      "Found cluster: 5.33% of datapoints\n",
      "Evaluating subgrid: 13.83% of datapoints\n",
      "Found following cuts: [(0.2143465027664646, 2, 5.5568701847565575e-06)]\n",
      "Evaluating subgrid: 8.50% of datapoints\n",
      "Found following cuts: [(0.8722138468063239, 0, 0.0011849466138673776)]\n",
      "Evaluating subgrid: 5.41% of datapoints\n",
      "Found following cuts: [(-0.29522658478129993, 5, 0.0016369591667595945)]\n",
      "Evaluating subgrid: 4.35% of datapoints\n",
      "Found cluster 52\n",
      "Evaluating subgrid: 4.35% of datapoints\n",
      "Found following cuts: [(-0.4974290361308089, 4, 0.04284510188976589)]\n",
      "Evaluating subgrid: 1.75% of datapoints\n",
      "Found cluster 53\n",
      "Evaluating subgrid: 1.75% of datapoints\n",
      "Found cluster 54\n",
      "Found cluster: 1.75% of datapoints\n",
      "Found cluster: 4.35% of datapoints\n",
      "Evaluating subgrid: 5.41% of datapoints\n",
      "Found cluster 55\n",
      "Found cluster: 5.41% of datapoints\n",
      "Evaluating subgrid: 8.50% of datapoints\n",
      "Found following cuts: [(-0.4694793236376059, 5, 0.011146848648682258)]\n",
      "Evaluating subgrid: 3.09% of datapoints\n",
      "Found cluster 56\n",
      "Evaluating subgrid: 3.09% of datapoints\n",
      "Found cluster 57\n",
      "Found cluster: 3.09% of datapoints\n",
      "Found cluster: 8.50% of datapoints\n",
      "Found cluster: 13.83% of datapoints\n",
      "Found cluster: 42.49% of datapoints\n",
      "Evaluating subgrid: 44.70% of datapoints\n",
      "Found cluster 58\n",
      "Found cluster: 44.70% of datapoints\n",
      "Found cluster: 82.71% of datapoints\n",
      "Found cluster: 83.78% of datapoints\n",
      "Found cluster: 90.66% of datapoints\n",
      "Evaluating subgrid: 95.01% of datapoints\n",
      "Found following cuts: [(0.5216877833761351, 1, 0.03375865414638669)]\n",
      "Evaluating subgrid: 4.36% of datapoints\n",
      "Found cluster 59\n",
      "Evaluating subgrid: 4.36% of datapoints\n",
      "Found cluster 60\n",
      "Found cluster: 4.36% of datapoints\n",
      "Found cluster: 95.01% of datapoints\n",
      "Found cluster: 100.00% of datapoints\n",
      "Optigrid found 61 clusters.\n",
      "Scoring voltage breakdowns\n",
      "Starting clustering for source stability 0\n",
      "Found following cuts: [(-6.799292203452852, 6, 0.0)]\n",
      "Evaluating subgrid: 100.00% of datapoints\n",
      "Found cluster 0\n",
      "Evaluating subgrid: 100.00% of datapoints\n",
      "Found following cuts: [(-1.8298402747722586, 2, 3.8561487949189916e-14)]\n",
      "Evaluating subgrid: 99.01% of datapoints\n",
      "Found following cuts: [(0.08082308733102028, 1, 0.00377870763016666)]\n",
      "Evaluating subgrid: 2.49% of datapoints\n",
      "Found cluster 1\n",
      "Evaluating subgrid: 2.49% of datapoints\n",
      "Found cluster 2\n",
      "Found cluster: 2.49% of datapoints\n",
      "Evaluating subgrid: 99.01% of datapoints\n",
      "Found following cuts: [(-3.1995042213285814, 7, 2.984447982125264e-52)]\n",
      "Evaluating subgrid: 96.52% of datapoints\n",
      "Found cluster 3\n",
      "Evaluating subgrid: 96.52% of datapoints\n",
      "Found following cuts: [(2.5490136291041523, 0, 0.00013837866827225525)]\n",
      "Evaluating subgrid: 95.14% of datapoints\n",
      "Found following cuts: [(-2.3634496168656782, 0, 0.0003040475869823756)]\n",
      "Evaluating subgrid: 93.13% of datapoints\n",
      "Found cluster 4\n",
      "Evaluating subgrid: 93.13% of datapoints\n",
      "Found following cuts: [(-0.9638832048936323, 3, 0.0005609492910106792)]\n",
      "Evaluating subgrid: 91.19% of datapoints\n",
      "Found following cuts: [(-1.4125913008294972, 4, 1.941757805833496e-06)]\n",
      "Evaluating subgrid: 32.52% of datapoints\n",
      "Found cluster 5\n",
      "Evaluating subgrid: 32.52% of datapoints\n",
      "Found following cuts: [(-0.505571524302165, 5, 0.0007247831480338484)]\n",
      "Evaluating subgrid: 31.05% of datapoints\n",
      "Found following cuts: [(0.06818065318194311, 2, 0.0001845070429303833)]\n",
      "Evaluating subgrid: 12.80% of datapoints\n",
      "Found following cuts: [(-0.5470882304991134, 0, 0.004383499207307442)]\n",
      "Evaluating subgrid: 7.34% of datapoints\n",
      "Found following cuts: [(-1.8568577983162622, 5, 0.0037600918631956436)]\n",
      "Evaluating subgrid: 5.38% of datapoints\n",
      "Found cluster 6\n",
      "Evaluating subgrid: 5.38% of datapoints\n",
      "Found following cuts: [(0.35065186866606135, 7, 0.033202702520132764)]\n",
      "Evaluating subgrid: 4.54% of datapoints\n",
      "Found cluster 7\n",
      "Evaluating subgrid: 4.54% of datapoints\n",
      "Found cluster 8\n",
      "Found cluster: 4.54% of datapoints\n",
      "Found cluster: 5.38% of datapoints\n",
      "Evaluating subgrid: 7.34% of datapoints\n",
      "Found cluster 9\n",
      "Found cluster: 7.34% of datapoints\n",
      "Evaluating subgrid: 12.80% of datapoints\n",
      "Found following cuts: [(-0.351763124417777, 0, 3.073919907715726e-05)]\n",
      "Evaluating subgrid: 5.46% of datapoints\n",
      "Found cluster 10\n",
      "Evaluating subgrid: 5.46% of datapoints\n",
      "Found cluster 11\n",
      "Found cluster: 5.46% of datapoints\n",
      "Found cluster: 12.80% of datapoints\n",
      "Evaluating subgrid: 31.05% of datapoints\n",
      "Found following cuts: [(0.5742296209238997, 5, 0.002431367372087718)]\n",
      "Evaluating subgrid: 18.25% of datapoints\n",
      "Found following cuts: [(-0.19112616115146208, 0, 0.005219977809068781)]\n",
      "Evaluating subgrid: 7.63% of datapoints\n",
      "Found following cuts: [(-0.28026496280323376, 2, 0.00515230962914966)]\n",
      "Evaluating subgrid: 6.44% of datapoints\n",
      "Found cluster 12\n",
      "Evaluating subgrid: 6.44% of datapoints\n",
      "Found following cuts: [(0.5085878095241507, 4, 0.007080643858589135)]\n",
      "Evaluating subgrid: 5.18% of datapoints\n",
      "Found following cuts: [(0.23777695617290462, 7, 0.020066414872600226)]\n",
      "Evaluating subgrid: 3.78% of datapoints\n",
      "Found cluster 13\n",
      "Evaluating subgrid: 3.78% of datapoints\n",
      "Found cluster 14\n",
      "Found cluster: 3.78% of datapoints\n",
      "Evaluating subgrid: 5.18% of datapoints\n",
      "Found cluster 15\n",
      "Found cluster: 5.18% of datapoints\n",
      "Found cluster: 6.44% of datapoints\n",
      "Evaluating subgrid: 7.63% of datapoints\n",
      "Found cluster 16\n",
      "Found cluster: 7.63% of datapoints\n",
      "Evaluating subgrid: 18.25% of datapoints\n",
      "Found following cuts: [(-0.20602584968913673, 0, 0.00013433011537639016)]\n",
      "Evaluating subgrid: 10.62% of datapoints\n",
      "Found following cuts: [(0.8362605041927762, 2, 0.004028959723801591)]\n",
      "Evaluating subgrid: 8.88% of datapoints\n",
      "Found following cuts: [(0.9222539380343273, 5, 0.00146005330049632)]\n",
      "Evaluating subgrid: 5.93% of datapoints\n",
      "Found cluster 17\n",
      "Evaluating subgrid: 5.93% of datapoints\n",
      "Found following cuts: [(0.4511756246740166, 7, 0.03447688948200521)]\n",
      "Evaluating subgrid: 4.22% of datapoints\n",
      "Found following cuts: [(0.6736390891701285, 4, 0.04908999030988545)]\n",
      "Evaluating subgrid: 2.15% of datapoints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found cluster 18\n",
      "Evaluating subgrid: 2.15% of datapoints\n",
      "Found cluster 19\n",
      "Found cluster: 2.15% of datapoints\n",
      "Evaluating subgrid: 4.22% of datapoints\n",
      "Found cluster 20\n",
      "Found cluster: 4.22% of datapoints\n",
      "Found cluster: 5.93% of datapoints\n",
      "Evaluating subgrid: 8.88% of datapoints\n",
      "Found following cuts: [(-0.31087365355154484, 1, 0.04921032474141101)]\n",
      "Evaluating subgrid: 2.94% of datapoints\n",
      "Found cluster 21\n",
      "Evaluating subgrid: 2.94% of datapoints\n",
      "Found following cuts: [(-0.1349804595564351, 1, 0.06378909100855813)]\n",
      "Evaluating subgrid: 1.83% of datapoints\n",
      "Found cluster 22\n",
      "Evaluating subgrid: 1.83% of datapoints\n",
      "Found cluster 23\n",
      "Found cluster: 1.83% of datapoints\n",
      "Found cluster: 2.94% of datapoints\n",
      "Found cluster: 8.88% of datapoints\n",
      "Evaluating subgrid: 10.62% of datapoints\n",
      "Found cluster 24\n",
      "Found cluster: 10.62% of datapoints\n",
      "Found cluster: 18.25% of datapoints\n",
      "Found cluster: 31.05% of datapoints\n",
      "Found cluster: 32.52% of datapoints\n",
      "Evaluating subgrid: 91.19% of datapoints\n",
      "Found following cuts: [(-2.348273714383443, 4, 0.003533906976858142)]\n",
      "Evaluating subgrid: 58.67% of datapoints\n",
      "Found following cuts: [(0.04005124833848761, 0, 0.0009337560212062885)]\n",
      "Evaluating subgrid: 3.06% of datapoints\n",
      "Found cluster 25\n",
      "Evaluating subgrid: 3.06% of datapoints\n",
      "Found cluster 26\n",
      "Found cluster: 3.06% of datapoints\n",
      "Evaluating subgrid: 58.67% of datapoints\n",
      "Found following cuts: [(-0.5598322020636655, 1, 0.006152849466428288)]\n",
      "Evaluating subgrid: 55.60% of datapoints\n",
      "Found following cuts: [(-0.5517443526874888, 0, 0.007998469948578299)]\n",
      "Evaluating subgrid: 3.76% of datapoints\n",
      "Found cluster 27\n",
      "Evaluating subgrid: 3.76% of datapoints\n",
      "Found cluster 28\n",
      "Found cluster: 3.76% of datapoints\n",
      "Evaluating subgrid: 55.60% of datapoints\n",
      "Found following cuts: [(-2.0136557203350645, 4, 0.009969226855614667)]\n",
      "Evaluating subgrid: 51.84% of datapoints\n",
      "Found cluster 29\n",
      "Evaluating subgrid: 51.84% of datapoints\n",
      "Found following cuts: [(2.2718866485537905, 2, 0.00782435728877299)]\n",
      "Evaluating subgrid: 50.13% of datapoints\n",
      "Found following cuts: [(-1.65382833553083, 4, 0.011689278331070373)]\n",
      "Evaluating subgrid: 48.05% of datapoints\n",
      "Found following cuts: [(0.15993910034497583, 1, 0.09163159740667454)]\n",
      "Evaluating subgrid: 3.76% of datapoints\n",
      "Found cluster 30\n",
      "Evaluating subgrid: 3.76% of datapoints\n",
      "Found cluster 31\n",
      "Found cluster: 3.76% of datapoints\n",
      "Evaluating subgrid: 48.05% of datapoints\n",
      "Found following cuts: [(-0.5916663516651501, 4, 0.015096509167536968)]\n",
      "Evaluating subgrid: 44.28% of datapoints\n",
      "Found following cuts: [(1.6256491295014972, 2, 0.0021470262932346182)]\n",
      "Evaluating subgrid: 10.85% of datapoints\n",
      "Found following cuts: [(0.5971078523481734, 2, 0.002918563553444514)]\n",
      "Evaluating subgrid: 9.82% of datapoints\n",
      "Found following cuts: [(-0.09435862965053987, 5, 0.0025628088973460965)]\n",
      "Evaluating subgrid: 8.13% of datapoints\n",
      "Found following cuts: [(-0.4278541044755416, 2, 0.0034547231724167886)]\n",
      "Evaluating subgrid: 5.16% of datapoints\n",
      "Found following cuts: [(-0.6973093760133994, 2, 0.06027947508052107)]\n",
      "Evaluating subgrid: 2.37% of datapoints\n",
      "Found cluster 32\n",
      "Evaluating subgrid: 2.37% of datapoints\n",
      "Found cluster 33\n",
      "Found cluster: 2.37% of datapoints\n",
      "Evaluating subgrid: 5.16% of datapoints\n",
      "Found following cuts: [(-0.08355131203478033, 2, 0.007031471264804576)]\n",
      "Evaluating subgrid: 2.80% of datapoints\n",
      "Found cluster 34\n",
      "Evaluating subgrid: 2.80% of datapoints\n",
      "Found cluster 35\n",
      "Found cluster: 2.80% of datapoints\n",
      "Found cluster: 5.16% of datapoints\n",
      "Evaluating subgrid: 8.13% of datapoints\n",
      "Found following cuts: [(0.140554382945552, 1, 0.03899047091707479)]\n",
      "Evaluating subgrid: 2.97% of datapoints\n",
      "Found cluster 36\n",
      "Evaluating subgrid: 2.97% of datapoints\n",
      "Found cluster 37\n",
      "Found cluster: 2.97% of datapoints\n",
      "Found cluster: 8.13% of datapoints\n",
      "Evaluating subgrid: 9.82% of datapoints\n",
      "Found following cuts: [(-1.3070267402764522, 4, 0.0021190273501634424)]\n",
      "Evaluating subgrid: 1.69% of datapoints\n",
      "Found cluster 38\n",
      "Evaluating subgrid: 1.69% of datapoints\n",
      "Found cluster 39\n",
      "Found cluster: 1.69% of datapoints\n",
      "Found cluster: 9.82% of datapoints\n",
      "Evaluating subgrid: 10.85% of datapoints\n",
      "Found cluster 40\n",
      "Found cluster: 10.85% of datapoints\n",
      "Evaluating subgrid: 44.28% of datapoints\n",
      "Found following cuts: [(-0.1620252349159934, 0, 0.018591694590860238)]\n",
      "Evaluating subgrid: 33.44% of datapoints\n",
      "Found following cuts: [(-0.049127737681070816, 5, 0.037383053556610174)]\n",
      "Evaluating subgrid: 2.68% of datapoints\n",
      "Found cluster 41\n",
      "Evaluating subgrid: 2.68% of datapoints\n",
      "Found cluster 42\n",
      "Found cluster: 2.68% of datapoints\n",
      "Evaluating subgrid: 33.44% of datapoints\n",
      "Found following cuts: [(0.8000512893753822, 2, 0.010482944833767383)]\n",
      "Evaluating subgrid: 30.75% of datapoints\n",
      "Found following cuts: [(-1.2148094393990256, 7, 0.02007178236317254)]\n",
      "Evaluating subgrid: 23.14% of datapoints\n",
      "Found cluster 43\n",
      "Evaluating subgrid: 23.14% of datapoints\n",
      "Found following cuts: [(0.5896505033126984, 4, 0.020010269920901644)]\n",
      "Evaluating subgrid: 22.14% of datapoints\n",
      "Found following cuts: [(0.2170787230886595, 6, 0.005481187962190782)]\n",
      "Evaluating subgrid: 10.28% of datapoints\n",
      "Found following cuts: [(0.061153139730896644, 2, 0.00762302838516424)]\n",
      "Evaluating subgrid: 6.49% of datapoints\n",
      "Found following cuts: [(-0.3266204242603947, 2, 0.01147298413190497)]\n",
      "Evaluating subgrid: 4.23% of datapoints\n",
      "Found following cuts: [(0.5956816143459744, 5, 0.019348897142299)]\n",
      "Evaluating subgrid: 3.10% of datapoints\n",
      "Found cluster 44\n",
      "Evaluating subgrid: 3.10% of datapoints\n",
      "Found cluster 45\n",
      "Found cluster: 3.10% of datapoints\n",
      "Evaluating subgrid: 4.23% of datapoints\n",
      "Found cluster 46\n",
      "Found cluster: 4.23% of datapoints\n",
      "Evaluating subgrid: 6.49% of datapoints\n",
      "Found cluster 47\n",
      "Found cluster: 6.49% of datapoints\n",
      "Evaluating subgrid: 10.28% of datapoints\n",
      "Found following cuts: [(-0.7119435457268146, 2, 0.0037329003563988743)]\n",
      "Evaluating subgrid: 3.80% of datapoints\n",
      "Found cluster 48\n",
      "Evaluating subgrid: 3.80% of datapoints\n",
      "Found following cuts: [(-0.4668679977908279, 5, 0.0009233834777486536)]\n",
      "Evaluating subgrid: 2.50% of datapoints\n",
      "Found cluster 49\n",
      "Evaluating subgrid: 2.50% of datapoints\n",
      "Found cluster 50\n",
      "Found cluster: 2.50% of datapoints\n",
      "Found cluster: 3.80% of datapoints\n",
      "Found cluster: 10.28% of datapoints\n",
      "Evaluating subgrid: 22.14% of datapoints\n",
      "Found following cuts: [(-0.4358764128251509, 5, 0.008994745200094715)]\n",
      "Evaluating subgrid: 11.86% of datapoints\n",
      "Found following cuts: [(0.4721412995472701, 0, 0.0006741835119519638)]\n",
      "Evaluating subgrid: 5.52% of datapoints\n",
      "Found cluster 51\n",
      "Evaluating subgrid: 5.52% of datapoints\n",
      "Found cluster 52\n",
      "Found cluster: 5.52% of datapoints\n",
      "Evaluating subgrid: 11.86% of datapoints\n",
      "Found following cuts: [(0.8397437451463757, 0, 0.008603389190862645)]\n",
      "Evaluating subgrid: 6.34% of datapoints\n",
      "Found following cuts: [(-0.11183984351880624, 5, 0.021169666457937452)]\n",
      "Evaluating subgrid: 5.13% of datapoints\n",
      "Found following cuts: [(0.1937039623958896, 0, 0.0020926110562985616)]\n",
      "Evaluating subgrid: 2.06% of datapoints\n",
      "Found cluster 53\n",
      "Evaluating subgrid: 2.06% of datapoints\n",
      "Found cluster 54\n",
      "Found cluster: 2.06% of datapoints\n",
      "Evaluating subgrid: 5.13% of datapoints\n",
      "Found following cuts: [(0.5200995218874228, 0, 0.016984551435627722)]\n",
      "Evaluating subgrid: 3.08% of datapoints\n",
      "Found cluster 55\n",
      "Evaluating subgrid: 3.08% of datapoints\n",
      "Found cluster 56\n",
      "Found cluster: 3.08% of datapoints\n",
      "Found cluster: 5.13% of datapoints\n",
      "Evaluating subgrid: 6.34% of datapoints\n",
      "Found cluster 57\n",
      "Found cluster: 6.34% of datapoints\n",
      "Found cluster: 11.86% of datapoints\n",
      "Found cluster: 22.14% of datapoints\n",
      "Found cluster: 23.14% of datapoints\n",
      "Evaluating subgrid: 30.75% of datapoints\n",
      "Found following cuts: [(0.41610687308841277, 4, 0.00033247021233763404)]\n",
      "Evaluating subgrid: 7.61% of datapoints\n",
      "Found following cuts: [(0.17454836735821733, 6, 0.00037470024159473266)]\n",
      "Evaluating subgrid: 6.06% of datapoints\n",
      "Found following cuts: [(1.2548026009039446, 2, 0.008368790394767924)]\n",
      "Evaluating subgrid: 2.83% of datapoints\n",
      "Found cluster 58\n",
      "Evaluating subgrid: 2.83% of datapoints\n",
      "Found cluster 59\n",
      "Found cluster: 2.83% of datapoints\n",
      "Evaluating subgrid: 6.06% of datapoints\n",
      "Found following cuts: [(0.1041727162370778, 7, 0.05469141760569996)]\n",
      "Evaluating subgrid: 3.24% of datapoints\n",
      "Found cluster 60\n",
      "Evaluating subgrid: 3.24% of datapoints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found cluster 61\n",
      "Found cluster: 3.24% of datapoints\n",
      "Found cluster: 6.06% of datapoints\n",
      "Evaluating subgrid: 7.61% of datapoints\n",
      "Found cluster 62\n",
      "Found cluster: 7.61% of datapoints\n",
      "Found cluster: 30.75% of datapoints\n",
      "Found cluster: 33.44% of datapoints\n",
      "Found cluster: 44.28% of datapoints\n",
      "Found cluster: 48.05% of datapoints\n",
      "Evaluating subgrid: 50.13% of datapoints\n",
      "Found following cuts: [(0.595610175469909, 3, 0.06295910641462461)]\n",
      "Evaluating subgrid: 2.08% of datapoints\n",
      "Found cluster 63\n",
      "Evaluating subgrid: 2.08% of datapoints\n",
      "Found cluster 64\n",
      "Found cluster: 2.08% of datapoints\n",
      "Found cluster: 50.13% of datapoints\n",
      "Found cluster: 51.84% of datapoints\n",
      "Found cluster: 55.60% of datapoints\n",
      "Found cluster: 58.67% of datapoints\n",
      "Found cluster: 91.19% of datapoints\n",
      "Found cluster: 93.13% of datapoints\n",
      "Evaluating subgrid: 95.14% of datapoints\n",
      "Found following cuts: [(3.3349704453439424, 0, 7.389693697606996e-05)]\n",
      "Evaluating subgrid: 2.01% of datapoints\n",
      "Found cluster 65\n",
      "Evaluating subgrid: 2.01% of datapoints\n",
      "Found cluster 66\n",
      "Found cluster: 2.01% of datapoints\n",
      "Found cluster: 95.14% of datapoints\n",
      "Found cluster: 96.52% of datapoints\n",
      "Found cluster: 99.01% of datapoints\n",
      "Found cluster: 100.00% of datapoints\n",
      "Optigrid found 67 clusters.\n",
      "Scoring voltage breakdowns\n"
     ]
    }
   ],
   "source": [
    "df_total[ProcessingFeatures.CLUSTER] = -1\n",
    "cluster(df_total, parameters, 1, optigrid_params)\n",
    "cluster(df_total, parameters, 0, optigrid_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Long term storage\n",
    "We will save the clustered data to a file.\n",
    "\n",
    "First, create the logging string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[11.12.2019 12:33:49] '['../Data_Preprocessed/Jan2018.csv', '../Data_Preprocessed/Feb2018.csv', '../Data_Preprocessed/Mar2018.csv', '../Data_Preprocessed/Apr2018.csv', '../Data_Preprocessed/May2018.csv', '../Data_Preprocessed/Jun2018.csv', '../Data_Preprocessed/Jul2018.csv', '../Data_Preprocessed/Aug2018.csv', '../Data_Preprocessed/Sep2018.csv', '../Data_Preprocessed/Oct2018.csv', '../Data_Preprocessed/Nov2018.csv']' cluster results saved to '../Data_Clustered/JanNov2018.csv'. Columns used: ['IP.NSRCGEN:BIASDISCAQNV', 'IP.NSRCGEN:GASAQN', 'IP.NSRCGEN:OVEN1AQNP', 'IP.SAIREM2:FORWARDPOWER', 'IP.SOLINJ.ACQUISITION:CURRENT', 'IP.SOLCEN.ACQUISITION:CURRENT', 'IP.SOLEXT.ACQUISITION:CURRENT', 'IP.NSRCGEN:SOURCEHTAQNI', 'ITF.BCT25:CURRENT']. Parameters used: {'d': 9, 'q': 1, 'max_cut_score': 0.1, 'noise_level': 0.05, 'kde_bandwidth': 0.06, 'verbose': True}\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d.%m.%Y %H:%M:%S\")\n",
    "\n",
    "logstring = \"[{}] \\'{}\\' cluster results saved to \\'{}\\'. Columns used: {}. Parameters used: {}\\n\".format(dt_string, input_paths, output_path, parameters, optigrid_params)\n",
    "with open(cluster_logfile, \"a\") as myfile:\n",
    "    myfile.write(logstring)\n",
    "\n",
    "logstring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can save the dataframe to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = df_total.astype({ProcessingFeatures.CLUSTER : 'int64'})\n",
    "df_total[df_total.shift(1)==df_total] = np.nan\n",
    "df_total.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_performance_dbi(values_scaled, optigrid.clusters, optigrid.num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette_coefficient(a, b):\n",
    "    if a < b:\n",
    "        return 1 - a/b\n",
    "    elif a == b:\n",
    "        return 0\n",
    "    else:\n",
    "        return b/a - 1\n",
    "    \n",
    "def cluster_performance_silhouette(df_total, values_scaled, clusters, source_stability, voltage_breakdown_selection, num_clusters):\n",
    "    mean_distances = np.array([np.array([np.sum(np.linalg.norm(values_scaled[cluster]-x, axis=1)) / len(cluster) for cluster in clusters]) for x in values_scaled])\n",
    "    optigrid_cluster = df_total.loc[source_stability & voltage_breakdown_selection, 'optigrid_cluster']\n",
    "    selector = np.ones((len(values_scaled), num_clusters), dtype=bool)\n",
    "    selector[range(len(values)), optigrid_cluster] = False\n",
    "    print(mean_distances)\n",
    "    print(optigrid_cluster)\n",
    "    print(selector)\n",
    "    print(np.ma.masked_array(mean_distances, ~selector))\n",
    "    df_total.loc[source_stability & voltage_breakdown_selection, 'mean_dist_same_cluster'] = np.amin(np.ma.masked_array(mean_distances, selector), axis=1)\n",
    "    df_total.loc[source_stability & voltage_breakdown_selection, 'min_mean_dist_different_cluster'] = np.amin(np.ma.masked_array(mean_distances, ~selector), axis=1)\n",
    "    df_total.loc[source_stability & voltage_breakdown_selection, 'silhouette'] = np.vectorize(silhouette_coefficient)(df_total.loc[source_stability & voltage_breakdown_selection, 'mean_dist_same_cluster'], df_total.loc[source_stability & voltage_breakdown_selection, 'min_mean_dist_different_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_pairs_euclid_squared_numpy(A, B):\n",
    "    sqrA = np.broadcast_to(np.sum(np.power(A, 2), 1).reshape(A.shape[0], 1), (A.shape[0], B.shape[0]))\n",
    "    sqrB = np.broadcast_to(np.sum(np.power(B, 2), 1).reshape(B.shape[0], 1), (B.shape[0], A.shape[0])).transpose()\n",
    "\n",
    "    return sqrA - 2*np.matmul(A, B.transpose()) + sqrB\n",
    "\n",
    "def cluster_performance_dbi(values_scaled, clusters, num_clusters):\n",
    "    print(\"values_scaled: {}\".format(values_scaled))\n",
    "    values_per_cluster = [np.take(values_scaled, c, axis=0) for c in clusters]\n",
    "    means = np.array([np.mean(c, axis=0) for c in values_per_cluster])\n",
    "    print(\"values_per_cluster: {}\".format(values_per_cluster[0][:10]))\n",
    "    print(\"means: {}\".format(means))\n",
    "    assigned_cluster_mean = np.zeros((len(values_scaled), len(values_scaled[0])))\n",
    "    for i, c in enumerate(clusters):\n",
    "        assigned_cluster_mean[c] = means[i]\n",
    "    print(\"assigned_cluster_mean: {}\".format(assigned_cluster_mean))\n",
    "        \n",
    "    dists_from_means = np.linalg.norm(values_scaled-assigned_cluster_mean, axis=1)\n",
    "    print(\"dists_from_means: {}\".format([dists_from_means[c] for c in clusters]))\n",
    "    s = np.array([np.sqrt(1./len(c) * np.sum(dists_from_means[c])) for c in clusters])\n",
    "    print(\"s: {}\".format(s))\n",
    "    \n",
    "    dists_between_clusters = all_pairs_euclid_squared_numpy(means, means)\n",
    "    np.fill_diagonal(dists_between_clusters, np.nan)\n",
    "    print(\"dists_between_clusters: {}\".format(dists_between_clusters))\n",
    "    \n",
    "    r = np.tile(s, (num_clusters, 1))\n",
    "    r = (r + r.T) / dists_between_clusters\n",
    "    print(\"r: {}\".format(r))\n",
    "    d = np.nanmax(r, axis=1)\n",
    "    dbi = np.mean(d)\n",
    "    print(\"Davies-Bouldin index per cluster: {}\".format(d))\n",
    "    print(\"Davies-Bouldin index total: {}\".format(dbi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_clusters(optigrid, data, parameters):\n",
    "    values = ['mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
    "    result = pd.DataFrame(columns = pd.MultiIndex.from_tuples([(p, v) for p in parameters for v in values] + [('DENSITY', 'count'), ('DENSITY', 'percentage')]))\n",
    "    result.index.name = 'OPTIGRID_CLUSTER'\n",
    "    \n",
    "    for i, cluster in enumerate(optigrid.clusters):\n",
    "        cluster_data = np.take(data, cluster, axis=0)\n",
    "        mean = np.mean(cluster_data, axis=0)\n",
    "        std = np.std(cluster_data, axis=0)\n",
    "        quantiles = np.quantile(cluster_data, [0, 0.25, 0.5, 0.75, 1], axis=0)\n",
    "        cluster_description = [[mean[i], std[i], quantiles[0][i], quantiles[1][i], quantiles[2][i], quantiles[3][i], quantiles[4][i]] for i in range(len(parameters))]\n",
    "        cluster_description = [item for sublist in cluster_description for item in sublist]\n",
    "        cluster_description.append(len(cluster))\n",
    "        cluster_description.append(len(cluster)/len(data)*100)\n",
    "        result.loc[i] = cluster_description\n",
    "    return result\n",
    "\n",
    "described = describe_clusters(optigrid, data, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "wanted_statistics = [[(param, 'mean'), (param, 'std')] for param in parameters]\n",
    "wanted_statistics = [item for sublist in wanted_statistics for item in sublist] + [('DENSITY', 'percentage')]\n",
    "\n",
    "num_of_clusters_to_print = 10\n",
    "described.sort_values(by=[('DENSITY', 'percentage')], ascending=False, inplace = True)\n",
    "print(\"Sum of densities of printed clusters: {:.1f}%\".format(described.head(n=num_of_clusters_to_print)[('DENSITY', 'percentage')].sum()))\n",
    "described.head(n=num_of_clusters_to_print)[wanted_statistics].round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualizing the clusters we will plot the densities of the parameters. For comparability we will use explicit ranges for the x-axis per parameter. Those ranges should be chosen beforehand by an expert to validate or falsify his intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_clusters = 6 # number of clusters to visualize\n",
    "data = df[parameters].values # We select the unscaled data again, because by clustering we did not change any ordering and this data corresponds to the real world\n",
    "num_datapoints = len(data)\n",
    "\n",
    "resolution = 200\n",
    "bandwidth = [1, 0.01, 1, 10, 0.1, 0.001]\n",
    "num_kde_samples = 40000\n",
    "\n",
    "parameter_ranges = [[0,0] for i in range(len(parameters))]\n",
    "parameter_ranges[0] = [-300, -200] # Biasdisc x-axis\n",
    "\n",
    "parameter_ranges[1] = [5.1, 5.3] # Gas x-axis\n",
    "#parameter_ranges[2] = [0, 3] # High voltage current x-axis\n",
    "parameter_ranges[2] = [200, 300] # SolCen current x-axis\n",
    "#parameter_ranges[3] = [900, 2100] # Forwardpower x-axis\n",
    "parameter_ranges[3] = [1200, 1300] # SolExt current x-axis\n",
    "parameter_ranges[4] = [5, 20] # Oven1 power x-axis\n",
    "parameter_ranges[5] = [0, 0.05] # BCT25 current x-axis\n",
    "\n",
    "best_clusters = sorted(optigrid.clusters, key=lambda x: len(x), reverse=True)\n",
    "for i, cluster in enumerate(best_clusters[:num_clusters]):\n",
    "    median = [described.iloc[i,described.columns.get_loc((param, '50%'))] for param in parameters]\n",
    "    plot_cluster(data, cluster, parameters, parameter_ranges, resolution=resolution, median=median, bandwidth=bandwidth, percentage_of_values=1, num_kde_samples=num_kde_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to find all high voltage breakdowns that correspond to the currently considered source stability, and find out to which cluster each datapoint belongs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_statistics.append(('num_of_breakdowns', ''))\n",
    "described.head(n=num_of_clusters_to_print)[wanted_statistics].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_statistics = [[(param, 'mean')] for param in parameters]\n",
    "wanted_statistics = [item for sublist in wanted_statistics for item in sublist] + [('num_of_breakdowns', '')]\n",
    "corr_described = described[wanted_statistics].corr()\n",
    "corr_described.style.background_gradient(cmap='coolwarm', axis=None).set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "wanted_statistics = [[(param, 'mean'), (param, 'std'),  (param, 'min'),  (param, 'max')] for param in parameters]\n",
    "wanted_statistics = [item for sublist in wanted_statistics for item in sublist]\n",
    "df_breakdowns.groupby('is_breakdown').describe()[wanted_statistics].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def d(x,y):\n",
    "    return np.linalg.norm(x-y)\n",
    "\n",
    "size = 10\n",
    "data = np.random.uniform(0, 1, (size, 1))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([np.sum(np.linalg.norm(data-x, axis=1)) for x in data]) / (size - 1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "values = [0, 2, 2, 2, 3, 3, 1]\n",
    "values = np.array([[x, x] for x in values])\n",
    "clusters = [[0, 6], [1, 2, 3], [4, 5]]\n",
    "\n",
    "values, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_performance_dbi(values, clusters, len(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "davies_bouldin_score(values, [0, 1, 1, 1, 2, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source_stable = 1\n",
    "print(\"Starting clustering for source stability {}\".format(source_stable))\n",
    "source_stability = df_total['source_stable'] == source_stable\n",
    "voltage_breakdown_selection = df_total['is_breakdown'] > 0\n",
    "\n",
    "values = select_values(df_total, parameters, source_stability, ~voltage_breakdown_selection) # First, get the data without breakdowns,\n",
    "scaler, values_scaled = scale_values(values, None) # standard scale it\n",
    "print(values_scaled)\n",
    "optigrid = run_optigrid(values_scaled, optigrid_params) # and compute the clusters.\n",
    "print(values_scaled)\n",
    "#assign_clusters_df_total(df_total, optigrid, len(values), source_stability, ~voltage_breakdown_selection) # Then, assign the found clusters to the original dataframe in a new column 'optigrid_clusters'\n",
    "print(\"Calculating cluster performance cluster performance\")\n",
    "#cluster_performance_silhouette(df_total, values_scaled, optigrid.clusters, source_stability, voltage_breakdown_selection, optigrid.num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
