{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytimber\n",
    "ldb = pytimber.LoggingDB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the output file and the times you want to download. Timber and pyTimber conflict with regards to the the times, probably because of winter and summertime. If you want to have data stored in Timber from 00:00 to 01:00, you might to request either from 01:00 to 02:00 or even 02:00 to 03:00. We have to account for this shift later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../ionsrcopt/source_features.py\n",
    "class SourceFeatures(object):\n",
    "    TIMESTAMP = 'UTC_TIME'\n",
    "    BIASDISCAQNV = 'IP.NSRCGEN:BIASDISCAQNV'\n",
    "    GASAQN = 'IP.NSRCGEN:GASAQN'\n",
    "    GASSASAQN = 'IP.NSRCGEN:GASSASAQN'\n",
    "    SOLINJ_CURRENT = 'IP.SOLINJ.ACQUISITION:CURRENT'\n",
    "    SOLCEN_CURRENT = 'IP.SOLCEN.ACQUISITION:CURRENT'\n",
    "    SOLEXT_CURRENT = 'IP.SOLEXT.ACQUISITION:CURRENT'\n",
    "    OVEN1AQNP = 'IP.NSRCGEN:OVEN1AQNP'\n",
    "    OVEN2AQNP = 'IP.NSRCGEN:OVEN2AQNP'\n",
    "    SOURCEHTAQNI = 'IP.NSRCGEN:SOURCEHTAQNI'\n",
    "    SAIREM2_FORWARDPOWER = 'IP.SAIREM2:FORWARDPOWER'\n",
    "    THOMSON_FORWARDPOWER = 'IP.NSRCGEN:RFTHOMSONAQNFWD'\n",
    "    BCT05_CURRENT = 'ITL.BCT05:CURRENT'\n",
    "    BCT25_CURRENT = 'ITF.BCT25:CURRENT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now select all parameters you are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(parameters_raw, parameters_scaled, t1, t2):\n",
    "    print(\"Loading Data in interval {} to {}\".format(t1, t2))\n",
    "    result = {}\n",
    "\n",
    "    if parameters_raw:\n",
    "        result = ldb.get(parameters_raw, t1, t2, unixtime=True)\n",
    "\n",
    "    for k, v in parameters_scaled.items():\n",
    "        data = ldb.getScaled(k, t1, t2, scaleAlgorithm=v['scale'], scaleInterval=v['interval'], scaleSize=v['size'], unixtime=True)\n",
    "        result.update(data)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import path\n",
    "\n",
    "def load_existing_data(filename, replace_column):\n",
    "    if not path.exists(filename):\n",
    "        print(\"The file {} does not yet exist, we will create a new one\".format(filename))\n",
    "        return pd.DataFrame(columns=[SourceFeatures.TIMESTAMP])\n",
    "    \n",
    "    print(\"Loading data from {}.\".format(filename))\n",
    "    if replace_column:\n",
    "        print(\"We will replace columns that already exist\")\n",
    "    else:\n",
    "        print(\"We will only append new columns\")\n",
    "        \n",
    "    df = pd.read_csv(filename)\n",
    "    return df\n",
    "\n",
    "def create_base_df(filename, replace_file, replace_column):\n",
    "    if replace_file:\n",
    "        df = pd.DataFrame(columns=[SourceFeatures.TIMESTAMP])\n",
    "    else:\n",
    "        df = load_existing_data(filename, replace_column)\n",
    "\n",
    "    df.set_index(SourceFeatures.TIMESTAMP, inplace = True)\n",
    "    df.index = pd.to_datetime(df.index).tz_localize('UTC')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def check_duplicate_times(time_series):\n",
    "    x = time_series.duplicated()\n",
    "    count = x[x].count()\n",
    "    if count > 0:\n",
    "        print(\"Time duplicates exist!\")\n",
    "\n",
    "def join_result(df, result):\n",
    "    print(\"Joining together result\")\n",
    "    for parameter, values in result.items():\n",
    "        print(\"For column {} {} datapoints exist.\".format(parameter, len(values[1])))\n",
    "\n",
    "        if parameter in df.columns:\n",
    "            print(\"Parameter {} is already in the data frame. There it has {} values. In the newly retrieved dataset it has {} values.\".format(parameter, df[parameter].count(), len(values[1])))\n",
    "            if not replace_column:\n",
    "                print(\"Skipping.\")\n",
    "                continue\n",
    "            else:\n",
    "                print(\"Removing old column.\")\n",
    "                df = df.drop(parameter, axis=1)\n",
    "                df = df.dropna(axis=0, how='all')\n",
    "\n",
    "        df_column = pd.DataFrame(columns=[SourceFeatures.TIMESTAMP, parameter])\n",
    "        df_column[SourceFeatures.TIMESTAMP] = pd.Series([datetime.fromtimestamp(timestamp, tz=pytz.utc) for timestamp in values[0]])\n",
    "        check_duplicate_times(df_column[SourceFeatures.TIMESTAMP])\n",
    "        df_column[parameter] = values[1]\n",
    "\n",
    "        df_column.set_index(SourceFeatures.TIMESTAMP, inplace = True)\n",
    "        df_column.dropna(inplace=True)\n",
    "\n",
    "        df = df.join(df_column, how='outer')\n",
    "\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    df.index = df.index.strftime('%Y-%m-%d %H:%M:%S.%f').str[:-3]\n",
    "    df.index.name = SourceFeatures.TIMESTAMP\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the timeindex is duplicated, we will only keep the first occurence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save the output to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(df, filename):\n",
    "    print(\"Saving result to {}\".format(filename))\n",
    "    df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename, t1, t2, parameters_raw, parameters_scaled, replace_file, replace_column):\n",
    "    result = get_result(parameters_raw, parameters_scaled, t1, t2)\n",
    "    df = create_base_df(filename, replace_file, replace_column)\n",
    "    df = join_result(df, result)\n",
    "    df = df[~df.index.duplicated(keep='first')].copy()\n",
    "    save_df(df, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_raw = [\n",
    "        SourceFeatures.BIASDISCAQNV, \n",
    "        SourceFeatures.GASAQN, \n",
    "        SourceFeatures.OVEN1AQNP,\n",
    "        SourceFeatures.SOLINJ_CURRENT,\n",
    "        SourceFeatures.SOLCEN_CURRENT,\n",
    "        SourceFeatures.SOLEXT_CURRENT,\n",
    "        SourceFeatures.SOURCEHTAQNI,\n",
    "        SourceFeatures.BCT25_CURRENT\n",
    "]\n",
    "parameters_scaled = {\n",
    "        SourceFeatures.THOMSON_FORWARDPOWER : {'scale' : 'AVG', 'interval' : 'SECOND', 'size' : '10'},\n",
    "        SourceFeatures.BCT05_CURRENT : {'scale' : 'AVG', 'interval' : 'MINUTE', 'size' : '2'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "def load_data(filename, year, month):\n",
    "    t1 = '{}-{:02d}-01 00:00:00.000'.format(year, month)\n",
    "    if month == 12:\n",
    "        month = 0\n",
    "        year += 1\n",
    "    \n",
    "    t2 = '{}-{:02d}-01 00:00:00.000'.format(year, month+1)\n",
    "\n",
    "    t1 = pytz.utc.localize(datetime.strptime(t1, '%Y-%m-%d %H:%M:%S.%f')).astimezone(tz=None)\n",
    "    t2 = pytz.utc.localize(datetime.strptime(t2, '%Y-%m-%d %H:%M:%S.%f')).astimezone(tz=None)\n",
    "    replace_file = False\n",
    "    replace_column = True\n",
    "    get_data(filename, t1, t2, parameters_raw, parameters_scaled, replace_file, replace_column)\n",
    "    print(\"Finished download of data {}/{}\\n\".format(month, year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data in interval 2015-04-01 02:00:00+02:00 to 2015-05-01 02:00:00+02:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytimber.pytimber:Variable IP.NSRCGEN:RFTHOMSONAQNFWD contains NaN values\n",
      "WARNING:pytimber.pytimber:Variable ITL.BCT05:CURRENT contains NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file ../Data_Raw/Apr2015.csv does not yet exist, we will create a new one\n",
      "Joining together result\n",
      "For column IP.NSRCGEN:BIASDISCAQNV 8440 datapoints exist.\n",
      "For column IP.NSRCGEN:GASAQN 9186 datapoints exist.\n",
      "For column IP.NSRCGEN:OVEN1AQNP 122 datapoints exist.\n",
      "For column IP.NSRCGEN:SOURCEHTAQNI 9383 datapoints exist.\n",
      "For column IP.SOLCEN.ACQUISITION:CURRENT 733 datapoints exist.\n",
      "For column IP.SOLEXT.ACQUISITION:CURRENT 64718 datapoints exist.\n",
      "For column IP.SOLINJ.ACQUISITION:CURRENT 128396 datapoints exist.\n",
      "For column ITF.BCT25:CURRENT 205405 datapoints exist.\n",
      "For column IP.NSRCGEN:RFTHOMSONAQNFWD 259200 datapoints exist.\n",
      "For column ITL.BCT05:CURRENT 21600 datapoints exist.\n",
      "Saving result to ../Data_Raw/Apr2015.csv\n",
      "Finished download of data 4/2015\n",
      "\n",
      "Loading Data in interval 2015-05-01 02:00:00+02:00 to 2015-06-01 02:00:00+02:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytimber.pytimber:Variable IP.NSRCGEN:RFTHOMSONAQNFWD contains NaN values\n",
      "WARNING:pytimber.pytimber:Variable ITL.BCT05:CURRENT contains NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file ../Data_Raw/May2015.csv does not yet exist, we will create a new one\n",
      "Joining together result\n",
      "For column IP.NSRCGEN:BIASDISCAQNV 11128 datapoints exist.\n",
      "For column IP.NSRCGEN:GASAQN 10159 datapoints exist.\n",
      "For column IP.NSRCGEN:OVEN1AQNP 11554 datapoints exist.\n",
      "For column IP.NSRCGEN:SOURCEHTAQNI 177733 datapoints exist.\n",
      "For column IP.SOLCEN.ACQUISITION:CURRENT 1104 datapoints exist.\n",
      "For column IP.SOLEXT.ACQUISITION:CURRENT 167049 datapoints exist.\n",
      "For column IP.SOLINJ.ACQUISITION:CURRENT 316453 datapoints exist.\n",
      "For column ITF.BCT25:CURRENT 11177 datapoints exist.\n",
      "For column IP.NSRCGEN:RFTHOMSONAQNFWD 267840 datapoints exist.\n",
      "For column ITL.BCT05:CURRENT 22320 datapoints exist.\n",
      "Saving result to ../Data_Raw/May2015.csv\n",
      "Finished download of data 5/2015\n",
      "\n",
      "Loading Data in interval 2015-06-01 02:00:00+02:00 to 2015-07-01 02:00:00+02:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytimber.pytimber:Variable IP.NSRCGEN:RFTHOMSONAQNFWD contains NaN values\n",
      "WARNING:pytimber.pytimber:Variable ITL.BCT05:CURRENT contains NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file ../Data_Raw/Jun2015.csv does not yet exist, we will create a new one\n",
      "Joining together result\n",
      "For column IP.NSRCGEN:BIASDISCAQNV 8975 datapoints exist.\n",
      "For column IP.NSRCGEN:GASAQN 10538 datapoints exist.\n",
      "For column IP.NSRCGEN:OVEN1AQNP 8805 datapoints exist.\n",
      "For column IP.NSRCGEN:SOURCEHTAQNI 269186 datapoints exist.\n",
      "For column IP.SOLCEN.ACQUISITION:CURRENT 1962 datapoints exist.\n",
      "For column IP.SOLEXT.ACQUISITION:CURRENT 68253 datapoints exist.\n",
      "For column IP.SOLINJ.ACQUISITION:CURRENT 153504 datapoints exist.\n",
      "For column ITF.BCT25:CURRENT 146328 datapoints exist.\n",
      "For column IP.NSRCGEN:RFTHOMSONAQNFWD 259200 datapoints exist.\n",
      "For column ITL.BCT05:CURRENT 21600 datapoints exist.\n",
      "Saving result to ../Data_Raw/Jun2015.csv\n",
      "Finished download of data 6/2015\n",
      "\n",
      "Loading Data in interval 2015-07-01 02:00:00+02:00 to 2015-08-01 02:00:00+02:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytimber.pytimber:Variable IP.NSRCGEN:RFTHOMSONAQNFWD contains NaN values\n",
      "WARNING:pytimber.pytimber:Variable ITL.BCT05:CURRENT contains NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file ../Data_Raw/Jul2015.csv does not yet exist, we will create a new one\n",
      "Joining together result\n",
      "For column IP.NSRCGEN:BIASDISCAQNV 9144 datapoints exist.\n",
      "For column IP.NSRCGEN:GASAQN 9560 datapoints exist.\n",
      "For column IP.NSRCGEN:OVEN1AQNP 8968 datapoints exist.\n",
      "For column IP.NSRCGEN:SOURCEHTAQNI 277255 datapoints exist.\n",
      "For column IP.SOLCEN.ACQUISITION:CURRENT 1783 datapoints exist.\n",
      "For column IP.SOLEXT.ACQUISITION:CURRENT 16552 datapoints exist.\n",
      "For column IP.SOLINJ.ACQUISITION:CURRENT 26292 datapoints exist.\n",
      "For column ITF.BCT25:CURRENT 402543 datapoints exist.\n",
      "For column IP.NSRCGEN:RFTHOMSONAQNFWD 267840 datapoints exist.\n",
      "For column ITL.BCT05:CURRENT 22320 datapoints exist.\n",
      "Saving result to ../Data_Raw/Jul2015.csv\n",
      "Finished download of data 7/2015\n",
      "\n",
      "Loading Data in interval 2015-08-01 02:00:00+02:00 to 2015-09-01 02:00:00+02:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytimber.pytimber:Variable IP.NSRCGEN:RFTHOMSONAQNFWD contains NaN values\n",
      "WARNING:pytimber.pytimber:Variable ITL.BCT05:CURRENT contains NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file ../Data_Raw/Aug2015.csv does not yet exist, we will create a new one\n",
      "Joining together result\n",
      "For column IP.NSRCGEN:BIASDISCAQNV 9202 datapoints exist.\n",
      "For column IP.NSRCGEN:GASAQN 10208 datapoints exist.\n",
      "For column IP.NSRCGEN:OVEN1AQNP 8901 datapoints exist.\n",
      "For column IP.NSRCGEN:SOURCEHTAQNI 288107 datapoints exist.\n",
      "For column IP.SOLCEN.ACQUISITION:CURRENT 3968 datapoints exist.\n",
      "For column IP.SOLEXT.ACQUISITION:CURRENT 14566 datapoints exist.\n",
      "For column IP.SOLINJ.ACQUISITION:CURRENT 23223 datapoints exist.\n",
      "For column ITF.BCT25:CURRENT 276972 datapoints exist.\n",
      "For column IP.NSRCGEN:RFTHOMSONAQNFWD 267840 datapoints exist.\n",
      "For column ITL.BCT05:CURRENT 22320 datapoints exist.\n",
      "Saving result to ../Data_Raw/Aug2015.csv\n",
      "Finished download of data 8/2015\n",
      "\n",
      "Loading Data in interval 2015-09-01 02:00:00+02:00 to 2015-10-01 02:00:00+02:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytimber.pytimber:Variable IP.NSRCGEN:RFTHOMSONAQNFWD contains NaN values\n",
      "WARNING:pytimber.pytimber:Variable ITL.BCT05:CURRENT contains NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file ../Data_Raw/Sep2015.csv does not yet exist, we will create a new one\n",
      "Joining together result\n",
      "For column IP.NSRCGEN:BIASDISCAQNV 8951 datapoints exist.\n",
      "For column IP.NSRCGEN:GASAQN 18400 datapoints exist.\n",
      "For column IP.NSRCGEN:OVEN1AQNP 8590 datapoints exist.\n",
      "For column IP.NSRCGEN:SOURCEHTAQNI 250216 datapoints exist.\n",
      "For column IP.SOLCEN.ACQUISITION:CURRENT 2007 datapoints exist.\n",
      "For column IP.SOLEXT.ACQUISITION:CURRENT 17698 datapoints exist.\n",
      "For column IP.SOLINJ.ACQUISITION:CURRENT 24504 datapoints exist.\n",
      "For column ITF.BCT25:CURRENT 294851 datapoints exist.\n",
      "For column IP.NSRCGEN:RFTHOMSONAQNFWD 259200 datapoints exist.\n",
      "For column ITL.BCT05:CURRENT 21600 datapoints exist.\n",
      "Saving result to ../Data_Raw/Sep2015.csv\n",
      "Finished download of data 9/2015\n",
      "\n",
      "Loading Data in interval 2015-10-01 02:00:00+02:00 to 2015-11-01 01:00:00+01:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytimber.pytimber:Variable IP.NSRCGEN:RFTHOMSONAQNFWD contains NaN values\n",
      "WARNING:pytimber.pytimber:Variable ITL.BCT05:CURRENT contains NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file ../Data_Raw/Oct2015.csv does not yet exist, we will create a new one\n",
      "Joining together result\n",
      "For column IP.NSRCGEN:BIASDISCAQNV 9140 datapoints exist.\n",
      "For column IP.NSRCGEN:GASAQN 11981 datapoints exist.\n",
      "For column IP.NSRCGEN:OVEN1AQNP 8913 datapoints exist.\n",
      "For column IP.NSRCGEN:SOURCEHTAQNI 250183 datapoints exist.\n",
      "For column IP.SOLCEN.ACQUISITION:CURRENT 1902 datapoints exist.\n",
      "For column IP.SOLEXT.ACQUISITION:CURRENT 17097 datapoints exist.\n",
      "For column IP.SOLINJ.ACQUISITION:CURRENT 25956 datapoints exist.\n",
      "For column ITF.BCT25:CURRENT 231242 datapoints exist.\n",
      "For column IP.NSRCGEN:RFTHOMSONAQNFWD 267840 datapoints exist.\n",
      "For column ITL.BCT05:CURRENT 22320 datapoints exist.\n",
      "Saving result to ../Data_Raw/Oct2015.csv\n",
      "Finished download of data 10/2015\n",
      "\n",
      "Loading Data in interval 2015-11-01 01:00:00+01:00 to 2015-12-01 01:00:00+01:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytimber.pytimber:Variable IP.NSRCGEN:RFTHOMSONAQNFWD contains NaN values\n",
      "WARNING:pytimber.pytimber:Variable ITL.BCT05:CURRENT contains NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file ../Data_Raw/Nov2015.csv does not yet exist, we will create a new one\n",
      "Joining together result\n",
      "For column IP.NSRCGEN:BIASDISCAQNV 8461 datapoints exist.\n",
      "For column IP.NSRCGEN:GASAQN 8993 datapoints exist.\n",
      "For column IP.NSRCGEN:OVEN1AQNP 8555 datapoints exist.\n",
      "For column IP.NSRCGEN:SOURCEHTAQNI 249023 datapoints exist.\n",
      "For column IP.SOLCEN.ACQUISITION:CURRENT 1567 datapoints exist.\n",
      "For column IP.SOLEXT.ACQUISITION:CURRENT 16907 datapoints exist.\n",
      "For column IP.SOLINJ.ACQUISITION:CURRENT 25889 datapoints exist.\n",
      "For column ITF.BCT25:CURRENT 261350 datapoints exist.\n",
      "For column IP.NSRCGEN:RFTHOMSONAQNFWD 259200 datapoints exist.\n",
      "For column ITL.BCT05:CURRENT 21600 datapoints exist.\n",
      "Saving result to ../Data_Raw/Nov2015.csv\n",
      "Finished download of data 11/2015\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_folder = '../Data_Raw/'\n",
    "\n",
    "year = 2015\n",
    "start_month = 'Apr'\n",
    "end_month = 'Nov'\n",
    "\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "for m in months[months.index(start_month):months.index(end_month)+1]:\n",
    "    filename = output_folder + '{}{}.csv'.format(m, year)\n",
    "    load_data(filename, year, months.index(m)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
