{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../source_features.py\n",
    "class SourceFeatures(object):\n",
    "    TIMESTAMP = 'UTC_TIME'\n",
    "    BIASDISCAQNV = 'IP.NSRCGEN:BIASDISCAQNV'\n",
    "    GASAQN = 'IP.NSRCGEN:GASAQN'\n",
    "    GASSASAQN = 'IP.NSRCGEN:GASSASAQN'\n",
    "    SOLINJ_CURRENT = 'IP.SOLINJ.ACQUISITION:CURRENT'\n",
    "    SOLCEN_CURRENT = 'IP.SOLCEN.ACQUISITION:CURRENT'\n",
    "    SOLEXT_CURRENT = 'IP.SOLEXT.ACQUISITION:CURRENT'\n",
    "    OVEN1AQNP = 'IP.NSRCGEN:OVEN1AQNP'\n",
    "    OVEN2AQNP = 'IP.NSRCGEN:OVEN2AQNP'\n",
    "    SOURCEHTAQNI = 'IP.NSRCGEN:SOURCEHTAQNI'\n",
    "    SOURCEHTAQNV = 'IP.NSRCGEN:SOURCEHTAQNV'\n",
    "    SAIREM2_FORWARDPOWER = 'IP.SAIREM2:FORWARDPOWER'\n",
    "    THOMSON_FORWARDPOWER = 'IP.NSRCGEN:RFTHOMSONAQNFWD'\n",
    "    SPARK_COUNTER = 'IP.NSRCGEN:SPARKS'\n",
    "    BCT05_CURRENT = 'ITL.BCT05:CURRENT'\n",
    "    BCT25_CURRENT = 'ITF.BCT25:CURRENT'\n",
    "    BCT41_CURRENT = 'ITH.BCT41:CURRENT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../processing_features.py\n",
    "class ProcessingFeatures(object):\n",
    "    SOURCE_RUNNING = 'source_running'\n",
    "    SOURCE_STABILITY = 'source_stable'\n",
    "    CLUSTER = 'optigrid_cluster'\n",
    "    HT_VOLTAGE_BREAKDOWN = 'ht_voltage_breakdown'\n",
    "    HT_SPARKS_COUNTER = 'ht_sparks_counter'\n",
    "    DATAPOINT_DURATION = 'datapoint_duration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../load_data.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def read_data_from_csv(filenames, cols_to_read, rows_to_read):\n",
    "    \"\"\" Read a csv file into a DataFrame\n",
    "\n",
    "    Parameters:\n",
    "        filenames (list string): Filenames. Concatenates all into one data frame\n",
    "        cols_to_read (list of string): The column names to read, None if everything should be read\n",
    "        rows_to_read (list of int): The rown numbers to read, None if everything should be read\n",
    "\n",
    "    Returns:\n",
    "        DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(filenames, str):\n",
    "        filenames = [filenames]\n",
    "\n",
    "    dfs = []\n",
    "\n",
    "    for filename in filenames:\n",
    "        print(\"Loading data from csv file \\'{}\\'\".format(filename))\n",
    "\n",
    "        try:\n",
    "            if cols_to_read is None:\n",
    "                df = pd.read_csv(filename)\n",
    "            else:\n",
    "                df = pd.read_csv(filename, usecols=cols_to_read)\n",
    "        except:\n",
    "            print(\"File {} does not exist or is not a csv file\". format(filename))\n",
    "            exit()\n",
    "\n",
    "        if not SourceFeatures.TIMESTAMP in df.columns:\n",
    "            print(\"No timestamp column was found. It must be named {}.\".format(SourceFeatures.TIMESTAMP))\n",
    "            exit()\n",
    "\n",
    "        df[SourceFeatures.TIMESTAMP] = pd.to_datetime(df[SourceFeatures.TIMESTAMP]) \n",
    "        df = df.set_index(SourceFeatures.TIMESTAMP)\n",
    "        \n",
    "        if not rows_to_read is None:\n",
    "            df = df.iloc[rows_to_read].copy()\n",
    "\n",
    "        dfs.append(df)        \n",
    "\n",
    "    result = pd.concat(dfs, axis=0, sort=False)\n",
    "    return result.sort_index()\n",
    "\n",
    "def convert_column_types(df):\n",
    "    \"\"\" Convert all columns of a Dataframe of measurements to single precision values.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame to be altered\n",
    "\n",
    "    Returns:\n",
    "        DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Converting column types...\")\n",
    "    conversions = {\n",
    "        SourceFeatures.BIASDISCAQNV : 'float32',\n",
    "        SourceFeatures.GASSASAQN : 'float32',\n",
    "        SourceFeatures.GASAQN : 'float32',\n",
    "        SourceFeatures.SOLINJ_CURRENT : 'float32',\n",
    "        SourceFeatures.SOLEXT_CURRENT : 'float32',\n",
    "        SourceFeatures.SOLCEN_CURRENT : 'float32',\n",
    "        SourceFeatures.OVEN1AQNP : 'float32',\n",
    "        SourceFeatures.OVEN2AQNP : 'float32',\n",
    "        SourceFeatures.SAIREM2_FORWARDPOWER : 'float32',\n",
    "        SourceFeatures.THOMSON_FORWARDPOWER : 'float32',\n",
    "        SourceFeatures.SOURCEHTAQNI : 'float32',\n",
    "        SourceFeatures.BCT05_CURRENT : 'float32',\n",
    "        SourceFeatures.BCT25_CURRENT : 'float32',\n",
    "        ProcessingFeatures.SOURCE_STABILITY : 'int32',\n",
    "        ProcessingFeatures.HT_VOLTAGE_BREAKDOWN : 'int32',\n",
    "        ProcessingFeatures.DATAPOINT_DURATION : 'float32',\n",
    "        ProcessingFeatures.CLUSTER : 'int32',\n",
    "        ProcessingFeatures.SOURCE_RUNNING : 'bool'\n",
    "    }\n",
    "\n",
    "    conversions_to_apply = { c : conversions[c] for c in df.columns }\n",
    "    return df.astype(conversions_to_apply)\n",
    "\n",
    "def add_previous_data(df, previous_data, fill_nan_with_zeros):\n",
    "    \"\"\" Given the data from the previous time interval, this method selects for each feature where past data exists the last row where it was non null and inserts these rows into the frame at the beginning\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The data frame with the data from the current time interval\n",
    "        previous_data (None or String or DataFrame): The data from the previous interval. If None, then this method does nothing. If it is a file, it loads the data from the file. If it is a data frame, the dataa is taken directly from there.\n",
    "\n",
    "    Returns:\n",
    "        Timestamp: This is the first timestamp of the original data frame. Everything before was added from previous data\n",
    "        DataFrame: The altered frame. It has a few rows at the beginning that include the data from before\n",
    "    \"\"\"\n",
    "    old_first_index = df.index[0]\n",
    "    new_rows = []\n",
    "\n",
    "    if not previous_data is None:\n",
    "        if isinstance(previous_data, str):\n",
    "            previous_data = read_data_from_csv(previous_data, [df.index.name] + list(df.columns), None)\n",
    "            previous_data = convert_column_types(previous_data)\n",
    "\n",
    "        if not isinstance(previous_data, pd.DataFrame):\n",
    "            raise TypeError(\"previous_data hast to either be None, a filename or a DataFrame\")\n",
    "\n",
    "        for column in df.columns:\n",
    "            if not column in previous_data.columns:\n",
    "                continue\n",
    "\n",
    "            last_index_with_data = previous_data[column].last_valid_index()\n",
    "            if last_index_with_data:\n",
    "                new_rows.append(previous_data.loc[last_index_with_data])\n",
    "\n",
    "    new_rows.sort(key=lambda x: x.name)\n",
    "\n",
    "    if fill_nan_with_zeros:\n",
    "        new_row = pd.Series(data=np.zeros(len(df.columns)), index=df.columns)\n",
    "        oldest_index = old_first_index if not new_rows else new_rows[0].name\n",
    "        new_row.name = oldest_index - pd.Timedelta('1 day')\n",
    "        new_rows.insert(0, new_row)\n",
    "\n",
    "    df_previous = pd.DataFrame(new_rows).drop_duplicates()\n",
    "    df_previous.index.name = df.index.name\n",
    "    df = df_previous.append(df)\n",
    "    return old_first_index, df\n",
    "\n",
    "def fill_columns(df, previous_data, fill_nan_with_zeros=False):\n",
    "    print(\"Forward filling missing values...\")\n",
    "\n",
    "    old_first_index, df = add_previous_data(df, previous_data, fill_nan_with_zeros)\n",
    "    df = df.fillna(method='ffill')\n",
    "    return df.loc[df.index >= old_first_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
