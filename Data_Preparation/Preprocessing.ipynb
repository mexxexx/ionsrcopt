{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading data from Timber, it has to be preprocessed. It has to be decided when the source was stable, when voltage breakdowns occured an so on. These are tasks that in practice only have to be done once, which is the reason why this notebook exists. One is able to specify a raw data file and this notebook will export a labeled one together with visualizations of the performed tasks so that a visual quality check can be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../ionsrcopt/load_data.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def read_data_from_csv(filename, cols_to_read, rows_to_read):\n",
    "    \"\"\" Read a csv file into a DataFrame\n",
    "\n",
    "    Parameters:\n",
    "        filename (string): Filename\n",
    "        cols_to_read (list of string): The column names to read, None if everything should be read\n",
    "        rows_to_read (list of int): The rown numbers to read, None if everything should be read\n",
    "\n",
    "    Returns:\n",
    "        DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Loading data from csv file \\'{}\\'\".format(filename))\n",
    "    if cols_to_read is None:\n",
    "        df = pd.read_csv(filename).fillna(method='ffill')\n",
    "    else:\n",
    "        df = pd.read_csv(filename, usecols=cols_to_read).fillna(method='ffill')\n",
    "\n",
    "    if rows_to_read is None:\n",
    "        return df\n",
    "    else:\n",
    "        return df.iloc[rows_to_read]\n",
    "\n",
    "def convert_column(df, column, type):\n",
    "    \"\"\" Converts the dtype of a column\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame containing the column\n",
    "        column (string): The column name\n",
    "        type (string): dtype the column should be converted to\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The altered DataFrame or the old one, if it did not contain the specified column\n",
    "    \"\"\"\n",
    "\n",
    "    if column in df.columns:\n",
    "        print(\"Converting column \\'{}\\' to \\'{}\\'\".format(column, type))\n",
    "        return df.astype({column:type})\n",
    "    else:\n",
    "        print(\"Column \\'{}\\' does not exist\".format(column))\n",
    "        return df\n",
    "\n",
    "def convert_column_types(df):\n",
    "    \"\"\" Convert all columns of a Dataframe of measurements to single precision values.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame to be altered\n",
    "\n",
    "    Returns:\n",
    "        DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Started type conversion of columns...\")\n",
    "    if 'Timestamp (UTC_TIME)' in df.columns:\n",
    "        print(\"Converting column \\'{}\\' to \\'{}\\'\".format('Timestamp (UTC_TIME)', 'datetime'))\n",
    "        df['Timestamp (UTC_TIME)'] = pd.to_datetime(df['Timestamp (UTC_TIME)']) \n",
    "    df = convert_column(df, 'IP.NSRCGEN:BIASDISCAQNV', 'float32')\n",
    "    df = convert_column(df, 'IP.NSRCGEN:GASSASAQN', 'float32')\n",
    "    df = convert_column(df, 'IP.NSRCGEN:SOURCEHTAQNI', 'float32')\n",
    "    df = convert_column(df, 'IP.SAIREM2:FORWARDPOWER', 'float32')\n",
    "    df = convert_column(df, 'IP.SOLCEN.ACQUISITION:CURRENT', 'float32')\n",
    "    df = convert_column(df, 'IP.SOLEXT.ACQUISITION:CURRENT', 'float32')\n",
    "    df = convert_column(df, 'IP.SOLINJ.ACQUISITION:CURRENT', 'float32')\n",
    "    df = convert_column(df, 'ITF.BCT15:CURRENT', 'float32')\n",
    "    df = convert_column(df, 'ITF.BCT25:CURRENT', 'float32')\n",
    "    df = convert_column(df, 'ITH.BCT41:CURRENT', 'float32')\n",
    "    df = convert_column(df, 'ITL.BCT05:CURRENT', 'float32')\n",
    "    return df\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\" Clean the data of measurements, that are outliers, e.g. spikes in the extraction current.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the measurements.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Cleaned data.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Filtering data...\")\n",
    "    if 'ITF.BCT15:CURRENT' in df.columns:\n",
    "        df['ITF.BCT25:CURRENT'] = df['ITF.BCT15:CURRENT'].apply(lambda x: np.nan if x < 0 else x)\n",
    "    if 'ITF.BCT25:CURRENT' in df.columns:\n",
    "        df['ITF.BCT25:CURRENT'] = df['ITF.BCT25:CURRENT'].apply(lambda x: np.nan if x < 0 else x)\n",
    "    if 'ITH.BCT41:CURRENT' in df.columns:\n",
    "        df['ITF.BCT25:CURRENT'] = df['ITF.BCT41:CURRENT'].apply(lambda x: np.nan if x < 0 else x)\n",
    "    if 'ITL.BCT05:CURRENT' in df.columns:\n",
    "        df['ITF.BCT25:CURRENT'] = df['ITF.BCT05:CURRENT'].apply(lambda x: np.nan if x < 0 else x)\n",
    "    if 'IP.NSRCGEN:OVEN1AQNP' in df.columns:\n",
    "        df['ITF.BCT25:CURRENT'] = df['IP.NSRCGEN:OVEN1AQNP'].apply(lambda x: np.nan if x < 4.5 else x)\n",
    "    if 'IP.SOLEXT.ACQUISITION:CURRENT' in df.columns:\n",
    "        df['ITF.BCT25:CURRENT'] = df['IP.SOLEXT.ACQUISITION:CURRENT'].apply(lambda x: np.nan if x < 1200 else x)\n",
    "    if 'IP.NSRCGEN:BIASDISCAQNV' in df.columns:\n",
    "        df['ITF.BCT25:CURRENT'] = df['IP.NSRCGEN:BIASDISCAQNV'].apply(lambda x: np.nan if x == 0 else x)\n",
    "    if 'IP.SAIREM2:FORWARDPOWER' in df.columns:\n",
    "        df['ITF.BCT25:CURRENT'] = df['IP.SAIREM2:FORWARDPOWER'].apply(lambda x: np.nan if x < 500 else x)\n",
    "    if 'IP.NSRCGEN:SOURCEHTAQNI' in df.columns:\n",
    "        df['ITF.BCT25:CURRENT'] = df['IP.NSRCGEN:SOURCEHTAQNI'].apply(lambda x: np.nan if x > 2.5 else x)\n",
    "    if 'IP.NSRCGEN:SOURCEHTAQNI' in df.columns:\n",
    "        df['ITF.BCT25:CURRENT'] = df['IP.NSRCGEN:SOURCEHTAQNI'].apply(lambda x: np.nan if x < 0.5 else x)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../ionsrcopt/source_stability.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def stability_mean_variance_classification(df, current_column, sliding_window_size=5000, minimum_mean=0.025, maximum_variance=0.00005):\n",
    "    \"\"\" Classifies all point in the data frame into the categories source stable/unstable, based on a rolling window and a minimum mean and maximum variance in this window.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The data input loaded as a DataFrame\n",
    "        current_column (string): name of the column that contains the beam current we are interested in, typically BCT25\n",
    "        sliding_window_size (int): size of the sliding window, by default 5000 (100 Minutes of data every 1.2 seconds)\n",
    "        minimum_mean (double): minimal intensity of the beam in the sliding window for it to be considered stable\n",
    "        maximum_variance (double): maximum variance of intensity of the beam in the sliding window for it to be considered stable\n",
    "\n",
    "    Returns:\n",
    "        Series: A series that for every data point indicates if the source was running stable or not (1 is stable, 0 is unstable)\n",
    "    \"\"\"\n",
    "\n",
    "    mean = np.array(df[current_column].rolling(sliding_window_size).mean())\n",
    "    var = np.array(df[current_column].rolling(sliding_window_size).var())\n",
    "\n",
    "    result = [int(m > minimum_mean and v < maximum_variance) if not np.isnan(m) and not np.isnan(v) else np.nan for (m, v) in zip(mean, var)]\n",
    "    return pd.Series(result, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '../Data_Raw/Nov2018.csv'\n",
    "output_file = '../Data_Preprocessed/Nov2018.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to read the data into a dataframe that we will manipulate and save afterwards. We will not do any column preselection at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data_from_csv(input_file, None, None)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we are going to do, is marking the source as stable/unstable. The parameters used are from experiments on the Nov2018 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'ITF.BCT25:CURRENT'\n",
    "sliding_window_size=5000\n",
    "minimum_mean=0.027\n",
    "maximum_variance=0.000035\n",
    "\n",
    "df['source_stable'] = stability_mean_variance_classification(df, column, sliding_window_size=sliding_window_size, minimum_mean=minimum_mean, maximum_variance=maximum_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we are interested in are the high voltage breakdowns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
