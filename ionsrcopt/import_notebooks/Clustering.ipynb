{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../grid_level.py\n",
    "class GridLevel:\n",
    "    \"\"\" Optigrid creates a nested partition of the input space. This data structure is used to represent a single level of the grid. Either it represents a cluster or it is devided further into subgrids \"\"\"\n",
    "\n",
    "    def __init__(self, cutting_planes, cluster_index):\n",
    "        \"\"\" Creates a grid level.\n",
    "\n",
    "        Parameters:\n",
    "            cutting_planes (list): The planes that are used to subdivide this grid level or None if it represents a cluster\n",
    "            cluster_index (int): The index of the represented cluster or None if it can be subdivided further\n",
    "        \"\"\"\n",
    "\n",
    "        self.cutting_planes = cutting_planes\n",
    "        self.cluster_index = cluster_index\n",
    "        self.subgrids = []\n",
    "        self.subgrid_indices = []\n",
    "\n",
    "    def add_subgrid(self, subgrid_index, subgrid):\n",
    "        \"\"\" Add a deeper level to the grid\n",
    "\n",
    "        Parameters:\n",
    "            subgrid_index (int): For every cutting plane, the subgrid can lay either right or left. This information can be used to binary encode it all at once. This is the subgrid index\n",
    "            subgrid (GridLevel): The subgrid to add\n",
    "        \"\"\"\n",
    "\n",
    "        self.subgrid_indices.append(subgrid_index)\n",
    "        self.subgrids.append(subgrid)\n",
    "\n",
    "    def get_sublevel(self, datapoint):\n",
    "        \"\"\" For a given datapoint returns the subgrid it lies in\n",
    "        \n",
    "        Parameters: \n",
    "            datapoint (ndarray): The datapoint\n",
    "        \n",
    "        Returns:\n",
    "            GridLevel: The subgrid or -1 if it belongs to no subgrid, meaning the point is an outlier.\n",
    "        \"\"\"\n",
    "\n",
    "        if datapoint is None:\n",
    "            raise ValueError(\"Datapoint must not be None.\")\n",
    "\n",
    "        grid_index = 0\n",
    "        for i, cut in enumerate(self.cutting_planes):\n",
    "            if datapoint[cut[1]] > cut[0]:\n",
    "                grid_index += 2 ** i\n",
    "\n",
    "        if not grid_index in self.subgrid_indices:\n",
    "            return -1\n",
    "\n",
    "        return self.subgrids[self.subgrid_indices.index(grid_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../optigrid.py\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "class Optigrid:\n",
    "    \"\"\" Implementation of the Optigrid Algorithm described in \"Optimal Grid-Clustering: Towards Breaking the Curse of Dimensionality in High-Dimensional Clustering\" by Hinneburg and Keim \"\"\"\n",
    "\n",
    "    def __init__(self, d, q, max_cut_score, noise_level, kde_bandwidth = None, kde_grid_ticks=100, kde_num_samples=15000, kde_atol=1E-6, kde_rtol=1E-4, verbose=False):\n",
    "        \"\"\" \n",
    "        Parameters:\n",
    "            d (int): Dimension of the data\n",
    "            q (int): Number of cutting planes per iteration\n",
    "            max_cut_score (double): Maximum density of a cutting plane\n",
    "        \"\"\"\n",
    "\n",
    "        self.d = d\n",
    "        self.q = q\n",
    "        self.max_cut_score = max_cut_score\n",
    "        self.noise_level = noise_level\n",
    "\n",
    "        self.root = None\n",
    "        self.clusters = None\n",
    "        self.num_clusters = -1\n",
    "\n",
    "        self.kde_bandwidth = kde_bandwidth\n",
    "        self.kde_grid_ticks = kde_grid_ticks\n",
    "        self.kde_num_samples = kde_num_samples\n",
    "        self.kde_atol = kde_atol\n",
    "        self.kde_rtol = kde_rtol\n",
    "\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, data, weights=None):\n",
    "        \"\"\" Find all clusters in the data. Clusters are stored as indices pointing to the passed data, i.e. if '10' is in cluster '0' means, that data[10] is in cluster 0.\n",
    "\n",
    "        Parameters:\n",
    "            data (ndarray): Each datapoint has to be an array of d dimensions\n",
    "        \"\"\"\n",
    "\n",
    "        data_count = len(data)\n",
    "        cluster_indices = np.array(range(data_count))\n",
    "\n",
    "        grid, clusters = self._iteration(data=data, weights=weights, cluster_indices=cluster_indices, percentage_of_values=1, last_cluster_name = [-1])\n",
    "        self.root = grid\n",
    "        self.clusters = clusters\n",
    "        self.num_clusters = len(clusters)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"Optigrid found {} clusters.\".format(self.num_clusters))\n",
    "\n",
    "    def _iteration(self, data, weights, cluster_indices, percentage_of_values, last_cluster_name):\n",
    "        \"\"\" Do one recursive step of the optigrid algorithm.\n",
    "\n",
    "        Parameters:\n",
    "            data (ndarray): Each datapoint has to be an array of d dimensions\n",
    "            cluster_indices (list of int): All indices that belong to the current cluster\n",
    "            percentage_of_values (double): Percentage of values that lay in the current cluster (0-1)\n",
    "            current_cluster (int): (passed as list to be mutable) The last cluster name that was found, -1 if none\n",
    "\n",
    "        Returns:\n",
    "            GridLevel: The gridlevel at the current step with all its depth\n",
    "            list of list of int: All clusters in the current data chunk\n",
    "        \"\"\"\n",
    "\n",
    "        cuts_iteration = []\n",
    "        for i in range(self.d): # First create all best cuts\n",
    "            cuts_iteration += self._create_cuts_kde(data, cluster_indices, current_dimension=i, percentage_of_values=percentage_of_values, weights=weights)\n",
    "        \n",
    "        if not cuts_iteration:\n",
    "            last_cluster_name[0] += 1\n",
    "            if self.verbose:\n",
    "                print(\"Found cluster {}\".format(last_cluster_name[0]))\n",
    "\n",
    "            return GridLevel(cutting_planes=None, cluster_index=last_cluster_name[0]), [cluster_indices]\n",
    "    \n",
    "        cuts_iteration = sorted(cuts_iteration, key=lambda x: x[2])[:self.q] # Sort the cuts based on the density at the minima and select the q best ones\n",
    "        if self.verbose:\n",
    "            print(\"Found following cuts: {}\".format(cuts_iteration))\n",
    "\n",
    "        grid = GridLevel(cutting_planes=cuts_iteration, cluster_index=None)\n",
    "        \n",
    "        grid_data = self._fill_grid(data, cluster_indices, cuts_iteration) # Fill the subgrid based on the cuts\n",
    "    \n",
    "        result = []\n",
    "        sum_weights_total = np.sum(weights[cluster_indices])\n",
    "        for i, cluster in enumerate(grid_data):\n",
    "            if cluster.size==0:\n",
    "                continue\n",
    "            sum_weights = np.sum(weights[cluster])\n",
    "\n",
    "            if self.verbose:\n",
    "                print(\"Evaluating subgrid: {:.2f}% of datapoints\".format(percentage_of_values*100))\n",
    "            subgrid, subresult = self._iteration(data=data, weights=weights, cluster_indices=cluster, percentage_of_values=percentage_of_values*sum_weights/sum_weights_total, last_cluster_name=last_cluster_name) # Run Optigrid on every subgrid\n",
    "            grid.add_subgrid(i, subgrid)\n",
    "            result += subresult\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"Found cluster: {:.2f}% of datapoints\".format(percentage_of_values*100))\n",
    "        return grid, result\n",
    "\n",
    "    def _fill_grid(self, data, cluster_indices, cuts):\n",
    "        \"\"\" Partitions the grid based on the selected cuts and assignes each cell the corresponding data points (as indices).\n",
    "        \n",
    "        Parameters:\n",
    "            data (ndarray): Each datapoint has to be an array of d dimensions\n",
    "            cluster_indices (list of int): All indices that belong to the current cluster\n",
    "            cuts (list): Cutting planes in the format (position, dimension, cutting_score)\n",
    "\n",
    "        Returns:\n",
    "            list of list of int: 2**num_cuts lists of indices representing the clusters in this level\n",
    "        \"\"\"\n",
    "        \n",
    "        num_cuts = len(cuts)\n",
    "        grid_index = np.zeros(len(cluster_indices))\n",
    "        for i, cut in enumerate(cuts):\n",
    "            cut_val = 2 ** i\n",
    "            grid_index[np.take(np.take(data, cut[1], axis=1), cluster_indices) > cut[0]] += cut_val\n",
    "\n",
    "        return [cluster_indices[grid_index==key] for key in range(2**num_cuts)]\n",
    "    \n",
    "    def _create_cuts_kde(self, data, cluster_indices, current_dimension, percentage_of_values, weights):\n",
    "        \"\"\" Find the best cuts in the specified dimension by estimating the data density using kde.\n",
    "\n",
    "        Parameters:\n",
    "            data (ndarray): Each datapoint has to be an array of d dimensions\n",
    "            cluster_indices (list of int): All indices that belong to the current cluster\n",
    "            current_dimension (int): Dimension on which to project\n",
    "            percentage_of_values (double): Percentage of values that lay in the current cluster (0-1)\n",
    "\n",
    "        Returns:\n",
    "            list: q best cuts in the format (position, dimension, cutting_score)\n",
    "        \"\"\"\n",
    "\n",
    "        grid, kde = self._estimate_distribution(data, cluster_indices, current_dimension, percentage_of_values=percentage_of_values, weights=weights) \n",
    "        kde = np.append(kde, 0)\n",
    "\n",
    "        peaks = self._find_peaks_distribution(kde)      \n",
    "        if not peaks:\n",
    "            return []\n",
    "\n",
    "        peaks = [peaks[0]] + sorted(sorted(peaks[1:-1], key=lambda x: kde[x], reverse=True)[:self.q - 1]) + [peaks[len(peaks) - 1]] # and get the q-1 most important peaks between the leftest and rightest one.\n",
    "        best_cuts = self._find_best_cuts(grid, kde, peaks, current_dimension)\n",
    "        return best_cuts\n",
    "\n",
    "    def _find_best_cuts(self, grid, kde, peaks, current_dimension):\n",
    "        \"\"\" Using a density estimate and its maxima, finds the best cutting planes\n",
    "        \n",
    "        Parameters:\n",
    "            grid (list of double): The grid on which the density estimate was evaluated\n",
    "            kde (list of double): For each point on the grid the corresponding density\n",
    "            peaks (list of double): The maxima of the density estimate on the grid\n",
    "            current_dimension (int): Dimension on which the data is projected\n",
    "\n",
    "        Returns:\n",
    "            list: Best cutting planes in this dimension in the format (position, dimension, cutting_score)\n",
    "        \"\"\"\n",
    "        best_cuts = [] \n",
    "        for i in range(len(peaks)-1): # between these peaks search for the optimal cutting plane\n",
    "            current_min = 1\n",
    "            current_min_index = -1\n",
    "            for j in range(peaks[i]+1, peaks[i+1]):\n",
    "                if kde[j] < current_min:\n",
    "                    current_min = kde[j]\n",
    "                    current_min_index = j\n",
    "            \n",
    "            if current_min_index >= 0 and current_min < self.max_cut_score:\n",
    "                best_cuts.append((grid[current_min_index], current_dimension, current_min)) # cutting plane format: (cutting coordinate, dimension in which we cut, density at minimum)\n",
    "        return best_cuts\n",
    "\n",
    "    def _find_peaks_distribution(self, kde):\n",
    "        \"\"\" Given a density distribution, locates its peaks\n",
    "\n",
    "        Parameters:\n",
    "            kde (list of double): The density estimates on an arbitrary 1D grid\n",
    "\n",
    "        Returns:\n",
    "            list of int: The corresponding indices of the grid where the kde has its peaks.\n",
    "        \"\"\"\n",
    "\n",
    "        peaks=[]\n",
    "        prev = 0\n",
    "        current = kde[0]\n",
    "        for bin in range(1, len(kde)): # Find all peaks that are above the noise level\n",
    "            next = kde[bin] \n",
    "            if current > prev and current > next and current >= self.noise_level:\n",
    "                peaks.append(bin-1)\n",
    "            prev = current\n",
    "            current = next\n",
    "        return peaks\n",
    "\n",
    "    def _estimate_distribution(self, data, cluster_indices, current_dimension, percentage_of_values, weights):\n",
    "        \"\"\" Estimate the distribution using a sample of the data projected to a coordinate axis using scikits kde estimate method\n",
    "\n",
    "        Parametes:\n",
    "            data (ndarray): Each datapoint has to be an array of d dimensions\n",
    "            cluster_indices (list of int): All indices that belong to the current cluster\n",
    "            current_dimension (int): Dimension on which to project\n",
    "            percentage_of_values (double): Percentage of values that lay in the current cluster (0-1)\n",
    "\n",
    "        Returns:\n",
    "            list of double: A equally spaced grid\n",
    "            list of double: The density on the grid points\n",
    "        \"\"\"\n",
    "\n",
    "        sample_size = min(self.kde_num_samples, len(cluster_indices))\n",
    "        sample = np.random.choice(cluster_indices, size=sample_size)\n",
    "        datapoints = data[sample][:,current_dimension]\n",
    "        weights_sample = None\n",
    "        if not weights is None:\n",
    "            weights_sample = weights[sample]\n",
    "        min_val = np.amin(datapoints)\n",
    "        max_val = np.amax(datapoints)\n",
    "\n",
    "        std = datapoints.std(ddof=1)\n",
    "        if np.isclose(std, 0, atol=1e-6):\n",
    "            return 0, np.infty\n",
    "\n",
    "        try:\n",
    "            kde = gaussian_kde(dataset=datapoints, bw_method=self.kde_bandwidth / std, weights=weights_sample)\n",
    "        except:\n",
    "            print('Something went wrong when calculating kde.') \n",
    "            print('Std: {}'.format(std))\n",
    "            print('data: {}'.format(datapoints))\n",
    "            return 0, np.infty\n",
    "\n",
    "        grid = np.linspace(min_val, max_val, self.kde_grid_ticks)\n",
    "        dens = kde.evaluate(grid)\n",
    "        return grid, dens * percentage_of_values\n",
    "\n",
    "    def score_samples(self, samples):\n",
    "        \"\"\" For every sample calculates the cluster it belongs to\n",
    "\n",
    "        Parameters:\n",
    "            samples (list of ndarray): The sample to score. They need to have the same dimensionality and scale as the data optigrid was fitted with\n",
    "        \n",
    "        Returns:\n",
    "            list of int: For every sample, the cluster it belongs to or None if it is in no cluster (only possible for q>1)\n",
    "        \"\"\"\n",
    "\n",
    "        return [self._score_sample(sample) for sample in samples]\n",
    "\n",
    "    def _score_sample(self, sample):\n",
    "        \"\"\" Score a single sample\n",
    "\n",
    "        Parameters:\n",
    "            sample (ndarray): Needs to have the same dimensionality and scale as the data optigrid was fitted with\n",
    "\n",
    "        Returns:\n",
    "            int: Cluster the sample belongs to ore None\n",
    "        \"\"\"\n",
    "\n",
    "        if self.root is None:\n",
    "            raise Exception(\"Optigrid needs to be fitted to a dataset first.\")\n",
    "\n",
    "        current_grid_level = self.root\n",
    "        while current_grid_level.cluster_index is None:\n",
    "            sub_level = current_grid_level.get_sublevel(sample)\n",
    "            if sub_level is None:\n",
    "                return None\n",
    "            \n",
    "            current_grid_level = sub_level\n",
    "\n",
    "        return current_grid_level.cluster_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
